{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hv_final_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1X_oXRNP_-TXi5KAdKvzVJBwXbqSruUa5",
      "authorship_tag": "ABX9TyOKh8rtaYdueY+fotH4ftbt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhil-mathews/MastersPr_Predicting-Human-Pathogen-PPIs-using-Natural-Language-Processing-methods/blob/main/4.Final_model/hv_final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgVaUCHS8e-F"
      },
      "source": [
        "### This is where the model is trained on a single train - test pair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDfJD8MItdQh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1db2e326-17cb-4f05-a1e7-589316afb4e0"
      },
      "source": [
        "import pandas as pd\n",
        "#Google colab does not have pickle\n",
        "try:\n",
        "  import pickle5 as pickle\n",
        "except:\n",
        "  !pip install pickle5\n",
        "  import pickle5 as pickle\n",
        "import os\n",
        "import seaborn as sns\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D,Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding,Concatenate\n",
        "from keras.models import Model,load_model\n",
        "from sklearn.metrics import roc_auc_score,confusion_matrix,roc_curve, auc\n",
        "from numpy import random\n",
        "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.metrics import AUC\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/ML_Data/')\n",
        "import functions as f\n",
        "\n",
        "directory = '/content/drive/MyDrive/ML_Data/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pickle5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/4c/5c4dd0462c8d3a6bc4af500a6af240763c2ebd1efdc736fc2c946d44b70a/pickle5-0.0.11.tar.gz (132kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 17.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 20.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 51kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 61kB 13.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 71kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 81kB 13.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 92kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 102kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 112kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 122kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 11.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp37-cp37m-linux_x86_64.whl size=219256 sha256=e7f91d522db61dd6ebf4520af801df59a3ced4c9a67d50a9cbde8eebe18e01ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/90/95/f889ca4aa8b0e0c7f21c8470b6f5d6032f0390a3a141a9a3bd\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgVaUCHS8e-F"
      },
      "source": [
        "### Pre-processed HV-PPI dataset looks like this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "eTqhCtJVgZDB",
        "outputId": "fa1a3bd6-d00b-48ba-a45e-0560c64eb37c"
      },
      "source": [
        "def load(name):\n",
        "    try:\n",
        "        with open(directory+''+name+'.pickle', 'rb') as handle:\n",
        "            return pickle.load(handle)\n",
        "    except:\n",
        "        with open(directory+''+name+'.pkl', 'rb') as handle:\n",
        "            return pickle.load(handle)\n",
        "\n",
        "df_train = load('HV_train')\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Human</th>\n",
              "      <th>Virus</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[M, E, R, A, V, P, L, A, V, P, L, G, Q, T, E, ...</td>\n",
              "      <td>[M, N, E, V, K, C, V, F, E, T, K, L, S, P, G, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[M, E, A, A, A, Q, F, F, V, E, S, P, D, V, V, ...</td>\n",
              "      <td>[M, A, E, E, Q, A, Y, H, V, N, K, G, L, E, C, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[M, D, A, N, S, K, D, K, P, P, E, T, K, E, S, ...</td>\n",
              "      <td>[M, K, L, L, V, G, I, L, V, A, V, C, L, H, Q, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[M, V, T, V, G, N, Y, C, E, A, E, G, P, V, G, ...</td>\n",
              "      <td>[M, A, R, F, E, D, P, T, R, R, P, Y, K, L, P, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[M, H, D, E, C, T, P, Q, Q, T, M, S, S, I, Q, ...</td>\n",
              "      <td>[M, T, A, T, P, L, T, N, L, F, L, R, A, P, D, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416890</th>\n",
              "      <td>[M, E, Q, Q, D, Q, S, M, K, E, G, R, L, T, L, ...</td>\n",
              "      <td>[M, A, F, Y, L, P, D, W, S, C, C, G, L, W, L, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416891</th>\n",
              "      <td>[M, M, A, A, E, A, G, S, E, E, G, G, P, V, T, ...</td>\n",
              "      <td>[M, A, K, A, T, G, R, Y, N, L, V, P, P, K, K, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416892</th>\n",
              "      <td>[M, N, G, V, S, E, G, T, R, G, C, S, D, R, Q, ...</td>\n",
              "      <td>[M, L, E, P, L, Q, I, L, S, I, C, S, F, I, L, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416893</th>\n",
              "      <td>[M, K, S, L, K, S, R, L, R, R, Q, D, V, P, G, ...</td>\n",
              "      <td>[M, R, P, G, R, P, L, A, G, F, Y, A, T, L, R, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416894</th>\n",
              "      <td>[M, N, N, S, Q, I, S, T, V, T, Q, F, V, L, L, ...</td>\n",
              "      <td>[M, A, P, P, G, M, R, L, R, S, G, R, S, T, G, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>416895 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "0                                                   Human  ... Label\n",
              "0       [M, E, R, A, V, P, L, A, V, P, L, G, Q, T, E, ...  ...     0\n",
              "1       [M, E, A, A, A, Q, F, F, V, E, S, P, D, V, V, ...  ...     0\n",
              "2       [M, D, A, N, S, K, D, K, P, P, E, T, K, E, S, ...  ...     0\n",
              "3       [M, V, T, V, G, N, Y, C, E, A, E, G, P, V, G, ...  ...     0\n",
              "4       [M, H, D, E, C, T, P, Q, Q, T, M, S, S, I, Q, ...  ...     0\n",
              "...                                                   ...  ...   ...\n",
              "416890  [M, E, Q, Q, D, Q, S, M, K, E, G, R, L, T, L, ...  ...     0\n",
              "416891  [M, M, A, A, E, A, G, S, E, E, G, G, P, V, T, ...  ...     0\n",
              "416892  [M, N, G, V, S, E, G, T, R, G, C, S, D, R, Q, ...  ...     0\n",
              "416893  [M, K, S, L, K, S, R, L, R, R, Q, D, V, P, G, ...  ...     0\n",
              "416894  [M, N, N, S, Q, I, S, T, V, T, Q, F, V, L, L, ...  ...     0\n",
              "\n",
              "[416895 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFW_ZElyWVTO"
      },
      "source": [
        "### They must be converted into a format usable by the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "2q6ZUjTMesbM",
        "outputId": "4d6261fd-1d46-485d-9d60-f9b2194e726c"
      },
      "source": [
        "df_train = df_train.rename(columns={'Virus':'Yersinia'})\n",
        "def join(df):\n",
        "  df[\"Joined\"] = [df.loc[row]['Human']+df.loc[row]['Yersinia'] for row in range(df.shape[0])]\n",
        "  return df\n",
        "join(df_train)\n",
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Human</th>\n",
              "      <th>Yersinia</th>\n",
              "      <th>Label</th>\n",
              "      <th>Joined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[M, E, R, A, V, P, L, A, V, P, L, G, Q, T, E, ...</td>\n",
              "      <td>[M, N, E, V, K, C, V, F, E, T, K, L, S, P, G, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[M, E, R, A, V, P, L, A, V, P, L, G, Q, T, E, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[M, E, A, A, A, Q, F, F, V, E, S, P, D, V, V, ...</td>\n",
              "      <td>[M, A, E, E, Q, A, Y, H, V, N, K, G, L, E, C, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[M, E, A, A, A, Q, F, F, V, E, S, P, D, V, V, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[M, D, A, N, S, K, D, K, P, P, E, T, K, E, S, ...</td>\n",
              "      <td>[M, K, L, L, V, G, I, L, V, A, V, C, L, H, Q, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[M, D, A, N, S, K, D, K, P, P, E, T, K, E, S, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[M, V, T, V, G, N, Y, C, E, A, E, G, P, V, G, ...</td>\n",
              "      <td>[M, A, R, F, E, D, P, T, R, R, P, Y, K, L, P, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[M, V, T, V, G, N, Y, C, E, A, E, G, P, V, G, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[M, H, D, E, C, T, P, Q, Q, T, M, S, S, I, Q, ...</td>\n",
              "      <td>[M, T, A, T, P, L, T, N, L, F, L, R, A, P, D, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[M, H, D, E, C, T, P, Q, Q, T, M, S, S, I, Q, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416890</th>\n",
              "      <td>[M, E, Q, Q, D, Q, S, M, K, E, G, R, L, T, L, ...</td>\n",
              "      <td>[M, A, F, Y, L, P, D, W, S, C, C, G, L, W, L, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[M, E, Q, Q, D, Q, S, M, K, E, G, R, L, T, L, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416891</th>\n",
              "      <td>[M, M, A, A, E, A, G, S, E, E, G, G, P, V, T, ...</td>\n",
              "      <td>[M, A, K, A, T, G, R, Y, N, L, V, P, P, K, K, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[M, M, A, A, E, A, G, S, E, E, G, G, P, V, T, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416892</th>\n",
              "      <td>[M, N, G, V, S, E, G, T, R, G, C, S, D, R, Q, ...</td>\n",
              "      <td>[M, L, E, P, L, Q, I, L, S, I, C, S, F, I, L, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[M, N, G, V, S, E, G, T, R, G, C, S, D, R, Q, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416893</th>\n",
              "      <td>[M, K, S, L, K, S, R, L, R, R, Q, D, V, P, G, ...</td>\n",
              "      <td>[M, R, P, G, R, P, L, A, G, F, Y, A, T, L, R, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[M, K, S, L, K, S, R, L, R, R, Q, D, V, P, G, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416894</th>\n",
              "      <td>[M, N, N, S, Q, I, S, T, V, T, Q, F, V, L, L, ...</td>\n",
              "      <td>[M, A, P, P, G, M, R, L, R, S, G, R, S, T, G, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[M, N, N, S, Q, I, S, T, V, T, Q, F, V, L, L, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>416895 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "0                                                   Human  ...                                             Joined\n",
              "0       [M, E, R, A, V, P, L, A, V, P, L, G, Q, T, E, ...  ...  [M, E, R, A, V, P, L, A, V, P, L, G, Q, T, E, ...\n",
              "1       [M, E, A, A, A, Q, F, F, V, E, S, P, D, V, V, ...  ...  [M, E, A, A, A, Q, F, F, V, E, S, P, D, V, V, ...\n",
              "2       [M, D, A, N, S, K, D, K, P, P, E, T, K, E, S, ...  ...  [M, D, A, N, S, K, D, K, P, P, E, T, K, E, S, ...\n",
              "3       [M, V, T, V, G, N, Y, C, E, A, E, G, P, V, G, ...  ...  [M, V, T, V, G, N, Y, C, E, A, E, G, P, V, G, ...\n",
              "4       [M, H, D, E, C, T, P, Q, Q, T, M, S, S, I, Q, ...  ...  [M, H, D, E, C, T, P, Q, Q, T, M, S, S, I, Q, ...\n",
              "...                                                   ...  ...                                                ...\n",
              "416890  [M, E, Q, Q, D, Q, S, M, K, E, G, R, L, T, L, ...  ...  [M, E, Q, Q, D, Q, S, M, K, E, G, R, L, T, L, ...\n",
              "416891  [M, M, A, A, E, A, G, S, E, E, G, G, P, V, T, ...  ...  [M, M, A, A, E, A, G, S, E, E, G, G, P, V, T, ...\n",
              "416892  [M, N, G, V, S, E, G, T, R, G, C, S, D, R, Q, ...  ...  [M, N, G, V, S, E, G, T, R, G, C, S, D, R, Q, ...\n",
              "416893  [M, K, S, L, K, S, R, L, R, R, Q, D, V, P, G, ...  ...  [M, K, S, L, K, S, R, L, R, R, Q, D, V, P, G, ...\n",
              "416894  [M, N, N, S, Q, I, S, T, V, T, Q, F, V, L, L, ...  ...  [M, N, N, S, Q, I, S, T, V, T, Q, F, V, L, L, ...\n",
              "\n",
              "[416895 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-23yfU65Wj-k"
      },
      "source": [
        "### Split into 50 datasets, converted to 5D and stored.\n",
        "\n",
        "This takes time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK-Zbhdx8LaF",
        "outputId": "1359e45d-fbf2-48ea-dead-b756b3f86056"
      },
      "source": [
        "#f.save(df_train,'HV_train_1D')\n",
        "df_train = f.load('HV_train_1D')\n",
        "\n",
        "multiple = df_train.shape[0]//50\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "not perfect. one datapoint is repeated across each subset, and some are lost.\n",
        "but considering the overall size, impact of this on result is zero\n",
        "\"\"\"\n",
        "for i in range(50):\n",
        "  print(i+1)\n",
        "  df = df_train.loc[multiple*i:multiple*(i+1)].reset_index(drop=True)\n",
        "  f.combine_AC(df,5)\n",
        "  #f.save(df,'HV_train_'+str(i)+'')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0FTPkMIW2AA"
      },
      "source": [
        "### 25GB RAM can only process half the training data for tokenizer creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rf2uUwm2ecy6",
        "outputId": "87d6ff91-952d-4398-e422-71200cd35f42"
      },
      "source": [
        "train_5D = f.load('HV_train_0')\n",
        "for i in range(1,25):\n",
        "  train_5D = pd.concat([train_5D,f.load('HV_train_'+str(i)+'')]).reset_index(drop=True)\n",
        "f.create_tokenizers(train_5D)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved tokenizers as doubleip_tkrs\n",
            "Saved tokenizer as join_tkr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GCfDqdbXECS"
      },
      "source": [
        "### Test data converted to 5D and saved, preprocessed and saved"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRmKlBMXejm4"
      },
      "source": [
        "df_test = f.load('HV_test_1D')\n",
        "f.combine_AC(df_test,5)\n",
        "#f.save(df_test,'HV_test_5D')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpWP8-gz-qJ2",
        "outputId": "46e9f365-37a8-4aef-d1e8-b819a8feed9d"
      },
      "source": [
        "df_test = f.load('HV_test_5D')\n",
        "tests = f.preprocess(df_test,saveTokrs=False)\n",
        "#f.save(tests,'tests')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NHHk0COXnRm"
      },
      "source": [
        "validation data during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBay9Jqx2UqI"
      },
      "source": [
        "df_test_5D = f.load('HV_test_5D')\n",
        "val_tests = df_test_5D.loc[:1500]\n",
        "#f.save(val_tests,'val_tests')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOuUyM0OlWbD"
      },
      "source": [
        "### The model is created and saved"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrlnO5jIfme0",
        "outputId": "3938837d-587f-49bd-fe74-0725e95d914d"
      },
      "source": [
        "EMBEDDING_DIM_5D = 50\n",
        "VALIDATION_SPLIT = 0.2\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 1\n",
        "DROP = 0.5\n",
        "threshold = 0.918\n",
        "MAX_SEQUENCE_LENGTH_5D_J = 2000\n",
        "MAX_SEQUENCE_LENGTH_5D_dIP = 1000\n",
        "num_words_5D_J = 1000000\n",
        "num_words_5D = 500000\n",
        "\n",
        "x1_join = f.transf_model(MAX_SEQUENCE_LENGTH_5D_J,num_words_5D_J,5,0.9)\n",
        "x2_join = f.transf_model(MAX_SEQUENCE_LENGTH_5D_J,num_words_5D_J,5,0.9)\n",
        "x3_join = f.transf_model(MAX_SEQUENCE_LENGTH_5D_J,num_words_5D_J,5,0.9)\n",
        "\n",
        "x1_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x2_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x3_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x4_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x5_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x6_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "\n",
        "concatenator = Concatenate(axis=1)\n",
        "x = concatenator([x1_join.output, x2_join.output, x3_join.output, x1_doubleip.output, x2_doubleip.output, x3_doubleip.output, x4_doubleip.output, x5_doubleip.output, x6_doubleip.output])\n",
        "x = Dense(256)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation=\"sigmoid\",name=\"Final\")(x)\n",
        "model_HV = Model(inputs=[x1_join.input, x2_join.input, x3_join.input, x1_doubleip.input, x2_doubleip.input, x3_doubleip.input, x4_doubleip.input, x5_doubleip.input, x6_doubleip.input], outputs=output)\n",
        "\n",
        "model_HV.compile(loss='binary_crossentropy', optimizer='adam', metrics=AUC())\n",
        "\n",
        "#model_HV.save(directory+'model_HV')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_24_layer_call_and_return_conditional_losses, embedding_24_layer_call_fn, embedding_25_layer_call_and_return_conditional_losses, embedding_25_layer_call_fn, embedding_26_layer_call_and_return_conditional_losses while saving (showing 5 of 195). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embedding_24_layer_call_and_return_conditional_losses, embedding_24_layer_call_fn, embedding_25_layer_call_and_return_conditional_losses, embedding_25_layer_call_fn, embedding_26_layer_call_and_return_conditional_losses while saving (showing 5 of 195). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_Data/model_HV/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_Data/model_HV/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vy13vIwf4Z6"
      },
      "source": [
        "### Trained on 2 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQoa2NvIvZY2",
        "outputId": "a7c3af20-d595-4d0f-f00b-4cc9c2efeca9"
      },
      "source": [
        "df_test = f.load('val_tests')\n",
        "val_tests = f.preprocess(df_test,saveTokrs=False)\n",
        "model_HV = load_model(directory+'model_HV')\n",
        "names = ['HV_train_'+str(i) for i in range(50)]\n",
        "\n",
        "for name in names+names:\n",
        "  print(name)\n",
        "  df_train = f.load(name)\n",
        "  trains = f.preprocess(df_train,saveTokrs=False)\n",
        "  model_HV.fit(trains, df_train['Label'].values, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(val_tests,df_test['Label'].values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing...\n",
            "HV_train_0\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 212s 793ms/step - loss: 0.1726 - auc_2: 0.6064 - val_loss: 0.1784 - val_auc_2: 0.7748\n",
            "HV_train_1\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 202s 772ms/step - loss: 0.1543 - auc_2: 0.7383 - val_loss: 0.1385 - val_auc_2: 0.8294\n",
            "HV_train_2\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 200s 768ms/step - loss: 0.1388 - auc_2: 0.7802 - val_loss: 0.1342 - val_auc_2: 0.8429\n",
            "HV_train_3\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 196s 749ms/step - loss: 0.1307 - auc_2: 0.8183 - val_loss: 0.1379 - val_auc_2: 0.8519\n",
            "HV_train_4\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 210s 803ms/step - loss: 0.1327 - auc_2: 0.8269 - val_loss: 0.1327 - val_auc_2: 0.8563\n",
            "HV_train_5\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 216s 828ms/step - loss: 0.1206 - auc_2: 0.8408 - val_loss: 0.1275 - val_auc_2: 0.8803\n",
            "HV_train_6\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 217s 832ms/step - loss: 0.1330 - auc_2: 0.8383 - val_loss: 0.1374 - val_auc_2: 0.8592\n",
            "HV_train_7\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 200s 768ms/step - loss: 0.1358 - auc_2: 0.8409 - val_loss: 0.1244 - val_auc_2: 0.8993\n",
            "HV_train_8\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 195s 749ms/step - loss: 0.1282 - auc_2: 0.8508 - val_loss: 0.1210 - val_auc_2: 0.8976\n",
            "HV_train_9\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 195s 748ms/step - loss: 0.1167 - auc_2: 0.8494 - val_loss: 0.1155 - val_auc_2: 0.9078\n",
            "HV_train_10\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 225s 862ms/step - loss: 0.1253 - auc_2: 0.8701 - val_loss: 0.1210 - val_auc_2: 0.8932\n",
            "HV_train_11\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 196s 751ms/step - loss: 0.1166 - auc_2: 0.8733 - val_loss: 0.1167 - val_auc_2: 0.9073\n",
            "HV_train_12\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 197s 757ms/step - loss: 0.1189 - auc_2: 0.8787 - val_loss: 0.1267 - val_auc_2: 0.9061\n",
            "HV_train_13\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 204s 780ms/step - loss: 0.1090 - auc_2: 0.8834 - val_loss: 0.1267 - val_auc_2: 0.9147\n",
            "HV_train_14\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 204s 783ms/step - loss: 0.1120 - auc_2: 0.8611 - val_loss: 0.1186 - val_auc_2: 0.9066\n",
            "HV_train_15\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 194s 744ms/step - loss: 0.1035 - auc_2: 0.8796 - val_loss: 0.1162 - val_auc_2: 0.9142\n",
            "HV_train_16\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 215s 825ms/step - loss: 0.1022 - auc_2: 0.8988 - val_loss: 0.1068 - val_auc_2: 0.9236\n",
            "HV_train_17\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 207s 792ms/step - loss: 0.1073 - auc_2: 0.8873 - val_loss: 0.1112 - val_auc_2: 0.9251\n",
            "HV_train_18\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 193s 740ms/step - loss: 0.1141 - auc_2: 0.9049 - val_loss: 0.1140 - val_auc_2: 0.9196\n",
            "HV_train_19\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 198s 758ms/step - loss: 0.1041 - auc_2: 0.9009 - val_loss: 0.1115 - val_auc_2: 0.9180\n",
            "HV_train_20\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 229s 877ms/step - loss: 0.1066 - auc_2: 0.9009 - val_loss: 0.1112 - val_auc_2: 0.9122\n",
            "HV_train_21\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 218s 836ms/step - loss: 0.1054 - auc_2: 0.9006 - val_loss: 0.1105 - val_auc_2: 0.9180\n",
            "HV_train_22\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 236s 904ms/step - loss: 0.1036 - auc_2: 0.9116 - val_loss: 0.1133 - val_auc_2: 0.9044\n",
            "HV_train_23\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 195s 749ms/step - loss: 0.1068 - auc_2: 0.8926 - val_loss: 0.1080 - val_auc_2: 0.9211\n",
            "HV_train_24\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 199s 763ms/step - loss: 0.1003 - auc_2: 0.9053 - val_loss: 0.1135 - val_auc_2: 0.9394\n",
            "HV_train_25\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 203s 779ms/step - loss: 0.1032 - auc_2: 0.8986 - val_loss: 0.1081 - val_auc_2: 0.9452\n",
            "HV_train_26\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 194s 743ms/step - loss: 0.1021 - auc_2: 0.9080 - val_loss: 0.1064 - val_auc_2: 0.9181\n",
            "HV_train_27\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 195s 745ms/step - loss: 0.1097 - auc_2: 0.8887 - val_loss: 0.1090 - val_auc_2: 0.9023\n",
            "HV_train_28\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 211s 807ms/step - loss: 0.1008 - auc_2: 0.9118 - val_loss: 0.1156 - val_auc_2: 0.9108\n",
            "HV_train_29\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 215s 822ms/step - loss: 0.1078 - auc_2: 0.8959 - val_loss: 0.1027 - val_auc_2: 0.9346\n",
            "HV_train_30\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 198s 758ms/step - loss: 0.1109 - auc_2: 0.8867 - val_loss: 0.1062 - val_auc_2: 0.9119\n",
            "HV_train_31\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 194s 745ms/step - loss: 0.0980 - auc_2: 0.9065 - val_loss: 0.1156 - val_auc_2: 0.8950\n",
            "HV_train_32\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 201s 769ms/step - loss: 0.1120 - auc_2: 0.8949 - val_loss: 0.1200 - val_auc_2: 0.9190\n",
            "HV_train_33\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 204s 783ms/step - loss: 0.1034 - auc_2: 0.8839 - val_loss: 0.1115 - val_auc_2: 0.9157\n",
            "HV_train_34\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 228s 873ms/step - loss: 0.1048 - auc_2: 0.9005 - val_loss: 0.1039 - val_auc_2: 0.9219\n",
            "HV_train_35\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 208s 798ms/step - loss: 0.1028 - auc_2: 0.9031 - val_loss: 0.1188 - val_auc_2: 0.9265\n",
            "HV_train_36\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 217s 830ms/step - loss: 0.1068 - auc_2: 0.8978 - val_loss: 0.1083 - val_auc_2: 0.9226\n",
            "HV_train_37\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 208s 796ms/step - loss: 0.1005 - auc_2: 0.9200 - val_loss: 0.1124 - val_auc_2: 0.9200\n",
            "HV_train_38\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 192s 736ms/step - loss: 0.0945 - auc_2: 0.9066 - val_loss: 0.1092 - val_auc_2: 0.9156\n",
            "HV_train_39\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 196s 751ms/step - loss: 0.0937 - auc_2: 0.9105 - val_loss: 0.1127 - val_auc_2: 0.9102\n",
            "HV_train_40\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 194s 741ms/step - loss: 0.0961 - auc_2: 0.9088 - val_loss: 0.1098 - val_auc_2: 0.9119\n",
            "HV_train_41\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 207s 795ms/step - loss: 0.1031 - auc_2: 0.9063 - val_loss: 0.1077 - val_auc_2: 0.9226\n",
            "HV_train_42\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 193s 738ms/step - loss: 0.1045 - auc_2: 0.9082 - val_loss: 0.1085 - val_auc_2: 0.9280\n",
            "HV_train_43\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 222s 849ms/step - loss: 0.1058 - auc_2: 0.9136 - val_loss: 0.1025 - val_auc_2: 0.9291\n",
            "HV_train_44\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 217s 830ms/step - loss: 0.0992 - auc_2: 0.9170 - val_loss: 0.1068 - val_auc_2: 0.9264\n",
            "HV_train_45\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 222s 851ms/step - loss: 0.0908 - auc_2: 0.9283 - val_loss: 0.1070 - val_auc_2: 0.9150\n",
            "HV_train_46\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 205s 785ms/step - loss: 0.1021 - auc_2: 0.9186 - val_loss: 0.0993 - val_auc_2: 0.9344\n",
            "HV_train_47\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 209s 803ms/step - loss: 0.0979 - auc_2: 0.9141 - val_loss: 0.1002 - val_auc_2: 0.9399\n",
            "HV_train_48\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 199s 763ms/step - loss: 0.0988 - auc_2: 0.9132 - val_loss: 0.1029 - val_auc_2: 0.9353\n",
            "HV_train_49\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 210s 803ms/step - loss: 0.0875 - auc_2: 0.9288 - val_loss: 0.0994 - val_auc_2: 0.9359\n",
            "HV_train_0\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 195s 747ms/step - loss: 0.0838 - auc_2: 0.9344 - val_loss: 0.1023 - val_auc_2: 0.9367\n",
            "HV_train_1\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 205s 785ms/step - loss: 0.0934 - auc_2: 0.9230 - val_loss: 0.1007 - val_auc_2: 0.9261\n",
            "HV_train_2\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 208s 796ms/step - loss: 0.0881 - auc_2: 0.9284 - val_loss: 0.1014 - val_auc_2: 0.9267\n",
            "HV_train_3\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 206s 787ms/step - loss: 0.0875 - auc_2: 0.9321 - val_loss: 0.1058 - val_auc_2: 0.9225\n",
            "HV_train_4\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 195s 746ms/step - loss: 0.0924 - auc_2: 0.9353 - val_loss: 0.1030 - val_auc_2: 0.9361\n",
            "HV_train_5\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 195s 748ms/step - loss: 0.0806 - auc_2: 0.9354 - val_loss: 0.1033 - val_auc_2: 0.9227\n",
            "HV_train_6\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 193s 740ms/step - loss: 0.0947 - auc_2: 0.9288 - val_loss: 0.1092 - val_auc_2: 0.9254\n",
            "HV_train_7\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 196s 749ms/step - loss: 0.0984 - auc_2: 0.9315 - val_loss: 0.1090 - val_auc_2: 0.9233\n",
            "HV_train_8\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 203s 778ms/step - loss: 0.0943 - auc_2: 0.9353 - val_loss: 0.1130 - val_auc_2: 0.9264\n",
            "HV_train_9\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 198s 760ms/step - loss: 0.0858 - auc_2: 0.9301 - val_loss: 0.1025 - val_auc_2: 0.9295\n",
            "HV_train_10\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 214s 819ms/step - loss: 0.0902 - auc_2: 0.9417 - val_loss: 0.1021 - val_auc_2: 0.9295\n",
            "HV_train_11\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 195s 745ms/step - loss: 0.0856 - auc_2: 0.9419 - val_loss: 0.0996 - val_auc_2: 0.9335\n",
            "HV_train_12\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 193s 739ms/step - loss: 0.0830 - auc_2: 0.9540 - val_loss: 0.1133 - val_auc_2: 0.9332\n",
            "HV_train_13\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 195s 745ms/step - loss: 0.0794 - auc_2: 0.9448 - val_loss: 0.1009 - val_auc_2: 0.9282\n",
            "HV_train_14\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 208s 795ms/step - loss: 0.0828 - auc_2: 0.9376 - val_loss: 0.1033 - val_auc_2: 0.9329\n",
            "HV_train_15\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 226s 868ms/step - loss: 0.0777 - auc_2: 0.9423 - val_loss: 0.1034 - val_auc_2: 0.9403\n",
            "HV_train_16\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 203s 776ms/step - loss: 0.0765 - auc_2: 0.9479 - val_loss: 0.1146 - val_auc_2: 0.9186\n",
            "HV_train_17\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 210s 805ms/step - loss: 0.0832 - auc_2: 0.9424 - val_loss: 0.1038 - val_auc_2: 0.9232\n",
            "HV_train_18\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 208s 798ms/step - loss: 0.0854 - auc_2: 0.9535 - val_loss: 0.1029 - val_auc_2: 0.9249\n",
            "HV_train_19\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 201s 768ms/step - loss: 0.0795 - auc_2: 0.9445 - val_loss: 0.0998 - val_auc_2: 0.9291\n",
            "HV_train_20\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 210s 807ms/step - loss: 0.0807 - auc_2: 0.9530 - val_loss: 0.1014 - val_auc_2: 0.9369\n",
            "HV_train_21\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 219s 839ms/step - loss: 0.0809 - auc_2: 0.9439 - val_loss: 0.1093 - val_auc_2: 0.9431\n",
            "HV_train_22\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 195s 747ms/step - loss: 0.0810 - auc_2: 0.9536 - val_loss: 0.0964 - val_auc_2: 0.9436\n",
            "HV_train_23\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 199s 764ms/step - loss: 0.0815 - auc_2: 0.9418 - val_loss: 0.1176 - val_auc_2: 0.9047\n",
            "HV_train_24\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 194s 744ms/step - loss: 0.0789 - auc_2: 0.9429 - val_loss: 0.1038 - val_auc_2: 0.9281\n",
            "HV_train_25\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 219s 840ms/step - loss: 0.0824 - auc_2: 0.9438 - val_loss: 0.0995 - val_auc_2: 0.9384\n",
            "HV_train_26\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 194s 745ms/step - loss: 0.0807 - auc_2: 0.9494 - val_loss: 0.1032 - val_auc_2: 0.9298\n",
            "HV_train_27\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 198s 759ms/step - loss: 0.0847 - auc_2: 0.9440 - val_loss: 0.1109 - val_auc_2: 0.9083\n",
            "HV_train_28\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 204s 781ms/step - loss: 0.0825 - auc_2: 0.9424 - val_loss: 0.1130 - val_auc_2: 0.9112\n",
            "HV_train_29\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 198s 759ms/step - loss: 0.0876 - auc_2: 0.9399 - val_loss: 0.0952 - val_auc_2: 0.9434\n",
            "HV_train_30\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 213s 817ms/step - loss: 0.0859 - auc_2: 0.9405 - val_loss: 0.0962 - val_auc_2: 0.9402\n",
            "HV_train_31\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 200s 765ms/step - loss: 0.0779 - auc_2: 0.9458 - val_loss: 0.0974 - val_auc_2: 0.9468\n",
            "HV_train_32\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 195s 745ms/step - loss: 0.0876 - auc_2: 0.9426 - val_loss: 0.1022 - val_auc_2: 0.9334\n",
            "HV_train_33\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 221s 848ms/step - loss: 0.0816 - auc_2: 0.9361 - val_loss: 0.1044 - val_auc_2: 0.9273\n",
            "HV_train_34\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 206s 790ms/step - loss: 0.0843 - auc_2: 0.9425 - val_loss: 0.1014 - val_auc_2: 0.9331\n",
            "HV_train_35\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 204s 780ms/step - loss: 0.0817 - auc_2: 0.9451 - val_loss: 0.1034 - val_auc_2: 0.9279\n",
            "HV_train_36\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 196s 749ms/step - loss: 0.0859 - auc_2: 0.9304 - val_loss: 0.1033 - val_auc_2: 0.9324\n",
            "HV_train_37\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 200s 767ms/step - loss: 0.0759 - auc_2: 0.9557 - val_loss: 0.1027 - val_auc_2: 0.9407\n",
            "HV_train_38\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 205s 785ms/step - loss: 0.0689 - auc_2: 0.9567 - val_loss: 0.1169 - val_auc_2: 0.9252\n",
            "HV_train_39\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 201s 769ms/step - loss: 0.0669 - auc_2: 0.9574 - val_loss: 0.0991 - val_auc_2: 0.9400\n",
            "HV_train_40\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 225s 861ms/step - loss: 0.0685 - auc_2: 0.9594 - val_loss: 0.0958 - val_auc_2: 0.9458\n",
            "HV_train_41\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 204s 780ms/step - loss: 0.0714 - auc_2: 0.9653 - val_loss: 0.0957 - val_auc_2: 0.9408\n",
            "HV_train_42\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 202s 772ms/step - loss: 0.0747 - auc_2: 0.9510 - val_loss: 0.0942 - val_auc_2: 0.9467\n",
            "HV_train_43\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 204s 781ms/step - loss: 0.0715 - auc_2: 0.9683 - val_loss: 0.0950 - val_auc_2: 0.9358\n",
            "HV_train_44\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 207s 792ms/step - loss: 0.0719 - auc_2: 0.9615 - val_loss: 0.1019 - val_auc_2: 0.9384\n",
            "HV_train_45\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 206s 790ms/step - loss: 0.0607 - auc_2: 0.9705 - val_loss: 0.0955 - val_auc_2: 0.9372\n",
            "HV_train_46\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 197s 756ms/step - loss: 0.0687 - auc_2: 0.9718 - val_loss: 0.0955 - val_auc_2: 0.9428\n",
            "HV_train_47\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 194s 743ms/step - loss: 0.0679 - auc_2: 0.9666 - val_loss: 0.0977 - val_auc_2: 0.9325\n",
            "HV_train_48\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 200s 768ms/step - loss: 0.0624 - auc_2: 0.9706 - val_loss: 0.0950 - val_auc_2: 0.9355\n",
            "HV_train_49\n",
            "Preprocessing...\n",
            "261/261 [==============================] - 217s 833ms/step - loss: 0.0585 - auc_2: 0.9665 - val_loss: 0.1097 - val_auc_2: 0.9456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0JXLGIUJAdk",
        "outputId": "5268b6ef-9e24-4482-e984-4a8796c18286"
      },
      "source": [
        "#model_HV.save(directory+'model_HV')\n",
        "model_HV = load_model(directory+'model_HV')\n",
        "df_test = f.load('HV_test_5D')\n",
        "roc_auc_score(df_test['Label'].values, model_HV.predict(f.load('tests')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9380718790442475"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    }
  ]
}
