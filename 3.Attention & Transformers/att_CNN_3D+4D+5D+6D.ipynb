{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "att_CNN_3D+4D+5D+6D.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1YB3Y13PaNhMHHtNiw5IQYUVB7JCeDqMt",
      "authorship_tag": "ABX9TyNfqs1EiNgMDN+jKlaWYHUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhil-mathews/MastersPr_Predicting-Human-Pathogen-PPIs-using-Natural-Language-Processing-methods/blob/main/3.Attention%20%26%20Transformers/att_CNN_3D%2B4D%2B5D%2B6D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isnmcaw5UqFv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "393bebaa-7bf5-4962-b3db-0a7ce53339ef"
      },
      "source": [
        "import pandas as pd\n",
        "#Google colab does not have pickle\n",
        "try:\n",
        "  import pickle5 as pickle\n",
        "except:\n",
        "  !pip install pickle5\n",
        "  import pickle5 as pickle\n",
        "import os\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D,Flatten, Attention\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding,  Concatenate, Lambda,RepeatVector,Dot\n",
        "from keras.models import Model\n",
        "from sklearn.metrics import roc_auc_score,confusion_matrix,roc_curve, auc\n",
        "from numpy import random\n",
        "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout, GlobalAveragePooling1D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/ML_Data/')\n",
        "import functions as f\n",
        "\n",
        "\n",
        "def load_data(D=1,randomize=False):\n",
        "    try:\n",
        "        with open('/content/drive/MyDrive/ML_Data/df_train_'+str(D)+'D.pickle', 'rb') as handle:\n",
        "            df_train = pickle.load(handle)\n",
        "    except:\n",
        "        df_train = pd.read_pickle(\"C:/Users/nik00/py/proj/hyppi-train.pkl\")\n",
        "    try:\n",
        "        with open('/content/drive/MyDrive/ML_Data/df_test_'+str(D)+'D.pickle', 'rb') as handle:\n",
        "            df_test = pickle.load(handle)\n",
        "    except:\n",
        "        df_test = pd.read_pickle(\"C:/Users/nik00/py/proj/hyppi-independent.pkl\")\n",
        "    if randomize:\n",
        "        return shuff_together(df_train,df_test)\n",
        "    else:\n",
        "        return df_train,df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pickle5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/4c/5c4dd0462c8d3a6bc4af500a6af240763c2ebd1efdc736fc2c946d44b70a/pickle5-0.0.11.tar.gz (132kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 51kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 71kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 81kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 92kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 102kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 112kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 122kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 8.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp37-cp37m-linux_x86_64.whl size=219272 sha256=83fe98c44a72b5cef19afbb95942043932f7d8a6278b7a46aae3c2c2c83c42bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/90/95/f889ca4aa8b0e0c7f21c8470b6f5d6032f0390a3a141a9a3bd\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "3ZnyI1lJUz0h",
        "outputId": "e26226f7-0c09-49d5-a5d3-aa838352479a"
      },
      "source": [
        "df_train,df_test = load_data(3)\n",
        "print('The data used will be:')\n",
        "df_train[['Human','Yersinia']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The data used will be:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Human</th>\n",
              "      <th>Yersinia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[MKD, KDK, DKQ, KQK, QKK, KKK, KKK, KKE, KER, ...</td>\n",
              "      <td>[MAK, AKA, KAS, ASR, SRH, RHN, HNL, NLS, LSI, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[MSW, SWS, WSG, SGL, GLL, LLH, LHG, HGL, GLN, ...</td>\n",
              "      <td>[MQH, QHV, HVT, VTG, TGS, GSK, SKR, KRR, RRL, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[MSL, SLF, LFD, FDL, DLF, LFR, FRG, RGF, GFF, ...</td>\n",
              "      <td>[MAE, AEL, ELP, LPA, PAK, AKR, KRR, RRF, RFT, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[MAV, AVA, VAP, APR, PRL, RLF, LFG, FGG, GGL, ...</td>\n",
              "      <td>[MRI, RIF, IFA, FAI, AIS, ISC, SCS, CSS, SSY, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[MST, STI, TIQ, IQS, QSE, SET, ETD, TDC, DCY, ...</td>\n",
              "      <td>[MSY, SYA, YAF, AFP, FPG, PGT, GTF, TFP, FPG, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6265</th>\n",
              "      <td>[MSY, SYF, YFG, FGE, GEH, EHF, HFW, FWG, WGE, ...</td>\n",
              "      <td>[MIT, ITT, TTD, TDG, DGN, GNS, NSA, SAV, AVA, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6266</th>\n",
              "      <td>[MTV, TVG, VGK, GKS, KSS, SSK, SKM, KML, MLQ, ...</td>\n",
              "      <td>[MSQ, SQP, QPP, PPF, PFW, FWQ, WQQ, QQK, QKT, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6267</th>\n",
              "      <td>[MNN, NNL, NLS, LSF, SFS, FSE, SEL, ELC, LCC, ...</td>\n",
              "      <td>[MSE, SED, EDR, DRH, RHQ, HQQ, QQR, QRQ, RQQ, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6268</th>\n",
              "      <td>[MAP, APE, PEI, EIN, INL, NLP, LPG, PGP, GPM, ...</td>\n",
              "      <td>[MKN, KNL, NLS, LSF, SFV, FVA, VAG, AGL, GLV, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6269</th>\n",
              "      <td>[MML, MLG, LGT, GTE, TEG, EGG, GGE, GEG, EGF, ...</td>\n",
              "      <td>[MVM, VMK, MKK, KKI, KIA, IAC, ACL, CLS, LSA, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6270 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Human                                           Yersinia\n",
              "0     [MKD, KDK, DKQ, KQK, QKK, KKK, KKK, KKE, KER, ...  [MAK, AKA, KAS, ASR, SRH, RHN, HNL, NLS, LSI, ...\n",
              "1     [MSW, SWS, WSG, SGL, GLL, LLH, LHG, HGL, GLN, ...  [MQH, QHV, HVT, VTG, TGS, GSK, SKR, KRR, RRL, ...\n",
              "2     [MSL, SLF, LFD, FDL, DLF, LFR, FRG, RGF, GFF, ...  [MAE, AEL, ELP, LPA, PAK, AKR, KRR, RRF, RFT, ...\n",
              "3     [MAV, AVA, VAP, APR, PRL, RLF, LFG, FGG, GGL, ...  [MRI, RIF, IFA, FAI, AIS, ISC, SCS, CSS, SSY, ...\n",
              "4     [MST, STI, TIQ, IQS, QSE, SET, ETD, TDC, DCY, ...  [MSY, SYA, YAF, AFP, FPG, PGT, GTF, TFP, FPG, ...\n",
              "...                                                 ...                                                ...\n",
              "6265  [MSY, SYF, YFG, FGE, GEH, EHF, HFW, FWG, WGE, ...  [MIT, ITT, TTD, TDG, DGN, GNS, NSA, SAV, AVA, ...\n",
              "6266  [MTV, TVG, VGK, GKS, KSS, SSK, SKM, KML, MLQ, ...  [MSQ, SQP, QPP, PPF, PFW, FWQ, WQQ, QQK, QKT, ...\n",
              "6267  [MNN, NNL, NLS, LSF, SFS, FSE, SEL, ELC, LCC, ...  [MSE, SED, EDR, DRH, RHQ, HQQ, QQR, QRQ, RQQ, ...\n",
              "6268  [MAP, APE, PEI, EIN, INL, NLP, LPG, PGP, GPM, ...  [MKN, KNL, NLS, LSF, SFV, FVA, VAG, AGL, GLV, ...\n",
              "6269  [MML, MLG, LGT, GTE, TEG, EGG, GGE, GEG, EGF, ...  [MVM, VMK, MKK, KKI, KIA, IAC, ACL, CLS, LSA, ...\n",
              "\n",
              "[6270 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6Tq2AjiU-gC",
        "outputId": "4b182cf2-53ff-480d-a21a-5aab9f256d34"
      },
      "source": [
        "data1,data2,data1_test,data2_test,num_words,MAX_SEQUENCE_LENGTH,MAX_VOCAB_SIZE = f.get_seq_data_doubleip(7000,1000,df_train,df_test, pad='pre')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAX_VOCAB_SIZE is 7000\n",
            "MAX_SEQUENCE_LENGTH is 1000\n",
            "max sequences1_train length: 8624\n",
            "min sequences1_train length: 37\n",
            "median sequences1_train length: 467\n",
            "max word index sequences1_train: 6999\n",
            "max sequences2_train length: 3704\n",
            "min sequences2_train length: 29\n",
            "median sequences2_train length: 329\n",
            "max word index sequences2_train: 6999\n",
            "Found 8000 unique tokens in tokenizer1.\n",
            "Found 7998 unique tokens in tokenizer2.\n",
            "pre padding\n",
            "Shape of data1 tensor: (6270, 1000)\n",
            "Shape of data2 tensor: (6270, 1000)\n",
            "max test_sequences1 length: 5530\n",
            "min test_sequences1 length: 37\n",
            "median test_sequences1 length: 484\n",
            "max test_sequences2 length: 3704\n",
            "min test_sequences2 length: 29\n",
            "median test_sequences2 length: 324\n",
            "pre padding for test seq.\n",
            "Shape of test_data1 tensor: (1514, 1000)\n",
            "Shape of test_data2 tensor: (1514, 1000)\n",
            "num_words is 7000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx2qiUfZWbrB",
        "outputId": "8b4089b1-fb11-40d8-859e-ca0881804946"
      },
      "source": [
        "EMBEDDING_DIM = 5\n",
        "VALIDATION_SPLIT = 0.2\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 20\n",
        "M_1D=10\n",
        "DROP = 0.6\n",
        "\n",
        "ip1 = f.att_model(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM,num_words,DROP)\n",
        "ip2 = f.att_model(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM,num_words,DROP)\n",
        "\n",
        "concatenator = Concatenate(axis=1)\n",
        "x = concatenator([ip1.output, ip2.output])\n",
        "x = Dense(128)(x)\n",
        "#x = concatenator([x1.output, x2.output]) # output is N x 4M\n",
        "#x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(DROP)(x)\n",
        "output = Dense(1, activation=\"sigmoid\",name=\"Final\")(x)\n",
        "model_doubleip = Model(inputs=[ip1.input,ip2.input], outputs=output)\n",
        "#plot_model(model1D_CNN_doubleip, to_file='model_plot.png', show_shapes=True, show_layer_names=False)\n",
        "model_doubleip.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "trains = [data1,data2,data2,data1]\n",
        "tests = [data1_test,data2_test,data2_test,data1_test]\n",
        "\n",
        "model_doubleip.fit(trains, df_train['label'].values,batch_size=BATCH_SIZE, epochs=EPOCHS,validation_data=(tests,df_test['label'].values))\n",
        "print(roc_auc_score(df_test['label'].values, model_doubleip.predict(tests)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "49/49 [==============================] - 9s 140ms/step - loss: 0.6651 - accuracy: 0.5956 - val_loss: 0.6089 - val_accuracy: 0.6651\n",
            "Epoch 2/20\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.6263 - accuracy: 0.6497 - val_loss: 0.5908 - val_accuracy: 0.6889\n",
            "Epoch 3/20\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.6117 - accuracy: 0.6628 - val_loss: 0.5816 - val_accuracy: 0.6968\n",
            "Epoch 4/20\n",
            "49/49 [==============================] - 7s 136ms/step - loss: 0.5868 - accuracy: 0.6814 - val_loss: 0.5635 - val_accuracy: 0.7094\n",
            "Epoch 5/20\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.5658 - accuracy: 0.7033 - val_loss: 0.5451 - val_accuracy: 0.7180\n",
            "Epoch 6/20\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.5429 - accuracy: 0.7169 - val_loss: 0.5368 - val_accuracy: 0.7186\n",
            "Epoch 7/20\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.5072 - accuracy: 0.7495 - val_loss: 0.5197 - val_accuracy: 0.7338\n",
            "Epoch 8/20\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.4847 - accuracy: 0.7583 - val_loss: 0.5006 - val_accuracy: 0.7437\n",
            "Epoch 9/20\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.4445 - accuracy: 0.7839 - val_loss: 0.4936 - val_accuracy: 0.7517\n",
            "Epoch 10/20\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.4328 - accuracy: 0.7896 - val_loss: 0.4995 - val_accuracy: 0.7457\n",
            "Epoch 11/20\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.3737 - accuracy: 0.8211 - val_loss: 0.4920 - val_accuracy: 0.7483\n",
            "Epoch 12/20\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.3366 - accuracy: 0.8457 - val_loss: 0.4917 - val_accuracy: 0.7616\n",
            "Epoch 13/20\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.3117 - accuracy: 0.8577 - val_loss: 0.5128 - val_accuracy: 0.7655\n",
            "Epoch 14/20\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.2856 - accuracy: 0.8688 - val_loss: 0.5093 - val_accuracy: 0.7853\n",
            "Epoch 15/20\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.2659 - accuracy: 0.8799 - val_loss: 0.5288 - val_accuracy: 0.7834\n",
            "Epoch 16/20\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.2350 - accuracy: 0.8895 - val_loss: 0.5974 - val_accuracy: 0.7721\n",
            "Epoch 17/20\n",
            "49/49 [==============================] - 7s 136ms/step - loss: 0.2056 - accuracy: 0.9103 - val_loss: 0.6651 - val_accuracy: 0.7774\n",
            "Epoch 18/20\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.1982 - accuracy: 0.9074 - val_loss: 0.6377 - val_accuracy: 0.7761\n",
            "Epoch 19/20\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.1983 - accuracy: 0.9134 - val_loss: 0.7132 - val_accuracy: 0.7787\n",
            "Epoch 20/20\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.1626 - accuracy: 0.9256 - val_loss: 0.6868 - val_accuracy: 0.7886\n",
            "0.8703924097241248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "lgpBUn3_iPJl",
        "outputId": "cf81314c-3dd5-439e-bd4d-800a30f74ed2"
      },
      "source": [
        "df_train,df_test = load_data(4)\n",
        "print('The data used will be:')\n",
        "df_train[['Human','Yersinia']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The data used will be:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Human</th>\n",
              "      <th>Yersinia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[MKDK, KDKQ, DKQK, KQKK, QKKK, KKKK, KKKE, KKE...</td>\n",
              "      <td>[MAKA, AKAS, KASR, ASRH, SRHN, RHNL, HNLS, NLS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[MSWS, SWSG, WSGL, SGLL, GLLH, LLHG, LHGL, HGL...</td>\n",
              "      <td>[MQHV, QHVT, HVTG, VTGS, TGSK, GSKR, SKRR, KRR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[MSLF, SLFD, LFDL, FDLF, DLFR, LFRG, FRGF, RGF...</td>\n",
              "      <td>[MAEL, AELP, ELPA, LPAK, PAKR, AKRR, KRRF, RRF...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[MAVA, AVAP, VAPR, APRL, PRLF, RLFG, LFGG, FGG...</td>\n",
              "      <td>[MRIF, RIFA, IFAI, FAIS, AISC, ISCS, SCSS, CSS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[MSTI, STIQ, TIQS, IQSE, QSET, SETD, ETDC, TDC...</td>\n",
              "      <td>[MSYA, SYAF, YAFP, AFPG, FPGT, PGTF, GTFP, TFP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6265</th>\n",
              "      <td>[MSYF, SYFG, YFGE, FGEH, GEHF, EHFW, HFWG, FWG...</td>\n",
              "      <td>[MITT, ITTD, TTDG, TDGN, DGNS, GNSA, NSAV, SAV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6266</th>\n",
              "      <td>[MTVG, TVGK, VGKS, GKSS, KSSK, SSKM, SKML, KML...</td>\n",
              "      <td>[MSQP, SQPP, QPPF, PPFW, PFWQ, FWQQ, WQQK, QQK...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6267</th>\n",
              "      <td>[MNNL, NNLS, NLSF, LSFS, SFSE, FSEL, SELC, ELC...</td>\n",
              "      <td>[MSED, SEDR, EDRH, DRHQ, RHQQ, HQQR, QQRQ, QRQ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6268</th>\n",
              "      <td>[MAPE, APEI, PEIN, EINL, INLP, NLPG, LPGP, PGP...</td>\n",
              "      <td>[MKNL, KNLS, NLSF, LSFV, SFVA, FVAG, VAGL, AGL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6269</th>\n",
              "      <td>[MMLG, MLGT, LGTE, GTEG, TEGG, EGGE, GGEG, GEG...</td>\n",
              "      <td>[MVMK, VMKK, MKKI, KKIA, KIAC, IACL, ACLS, CLS...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6270 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Human                                           Yersinia\n",
              "0     [MKDK, KDKQ, DKQK, KQKK, QKKK, KKKK, KKKE, KKE...  [MAKA, AKAS, KASR, ASRH, SRHN, RHNL, HNLS, NLS...\n",
              "1     [MSWS, SWSG, WSGL, SGLL, GLLH, LLHG, LHGL, HGL...  [MQHV, QHVT, HVTG, VTGS, TGSK, GSKR, SKRR, KRR...\n",
              "2     [MSLF, SLFD, LFDL, FDLF, DLFR, LFRG, FRGF, RGF...  [MAEL, AELP, ELPA, LPAK, PAKR, AKRR, KRRF, RRF...\n",
              "3     [MAVA, AVAP, VAPR, APRL, PRLF, RLFG, LFGG, FGG...  [MRIF, RIFA, IFAI, FAIS, AISC, ISCS, SCSS, CSS...\n",
              "4     [MSTI, STIQ, TIQS, IQSE, QSET, SETD, ETDC, TDC...  [MSYA, SYAF, YAFP, AFPG, FPGT, PGTF, GTFP, TFP...\n",
              "...                                                 ...                                                ...\n",
              "6265  [MSYF, SYFG, YFGE, FGEH, GEHF, EHFW, HFWG, FWG...  [MITT, ITTD, TTDG, TDGN, DGNS, GNSA, NSAV, SAV...\n",
              "6266  [MTVG, TVGK, VGKS, GKSS, KSSK, SSKM, SKML, KML...  [MSQP, SQPP, QPPF, PPFW, PFWQ, FWQQ, WQQK, QQK...\n",
              "6267  [MNNL, NNLS, NLSF, LSFS, SFSE, FSEL, SELC, ELC...  [MSED, SEDR, EDRH, DRHQ, RHQQ, HQQR, QQRQ, QRQ...\n",
              "6268  [MAPE, APEI, PEIN, EINL, INLP, NLPG, LPGP, PGP...  [MKNL, KNLS, NLSF, LSFV, SFVA, FVAG, VAGL, AGL...\n",
              "6269  [MMLG, MLGT, LGTE, GTEG, TEGG, EGGE, GGEG, GEG...  [MVMK, VMKK, MKKI, KKIA, KIAC, IACL, ACLS, CLS...\n",
              "\n",
              "[6270 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42qVtSSEiPal",
        "outputId": "523de711-e0be-45fd-fc24-58916f689df6"
      },
      "source": [
        " data1,data2,data1_test,data2_test,num_words,MAX_SEQUENCE_LENGTH,MAX_VOCAB_SIZE = f.get_seq_data_doubleip(100000,1000,df_train,df_test,pad = 'pre')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAX_VOCAB_SIZE is 100000\n",
            "MAX_SEQUENCE_LENGTH is 1000\n",
            "max sequences1_train length: 8063\n",
            "min sequences1_train length: 34\n",
            "median sequences1_train length: 440\n",
            "max word index sequences1_train: 99999\n",
            "max sequences2_train length: 3707\n",
            "min sequences2_train length: 26\n",
            "median sequences2_train length: 320\n",
            "max word index sequences2_train: 99999\n",
            "Found 155225 unique tokens in tokenizer1.\n",
            "Found 134906 unique tokens in tokenizer2.\n",
            "pre padding\n",
            "Shape of data1 tensor: (6270, 1000)\n",
            "Shape of data2 tensor: (6270, 1000)\n",
            "max test_sequences1 length: 5224\n",
            "min test_sequences1 length: 34\n",
            "median test_sequences1 length: 449\n",
            "max test_sequences2 length: 3707\n",
            "min test_sequences2 length: 24\n",
            "median test_sequences2 length: 308\n",
            "pre padding for test seq.\n",
            "Shape of test_data1 tensor: (1514, 1000)\n",
            "Shape of test_data2 tensor: (1514, 1000)\n",
            "num_words is 100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBGtu8ev7V_W",
        "outputId": "853b6c2d-1d51-4c7a-eb93-cc1377959ef2"
      },
      "source": [
        "EMBEDDING_DIM = 10\n",
        "VALIDATION_SPLIT = 0.2\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "M_1D=10\n",
        "DROP = 0.7\n",
        "\n",
        "ip1 = f.att_model(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM,num_words,DROP)\n",
        "ip2 = f.att_model(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM,num_words,DROP)\n",
        "\n",
        "concatenator = Concatenate(axis=1)\n",
        "x = concatenator([ip1.output, ip2.output])\n",
        "x = Dense(128)(x)\n",
        "#x = concatenator([x1.output, x2.output]) # output is N x 4M\n",
        "#x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(DROP)(x)\n",
        "output = Dense(1, activation=\"sigmoid\",name=\"Final\")(x)\n",
        "model_doubleip = Model(inputs=[ip1.input,ip2.input], outputs=output)\n",
        "#plot_model(model1D_CNN_doubleip, to_file='model_plot.png', show_shapes=True, show_layer_names=False)\n",
        "model_doubleip.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "trains = [data1,data2,data2,data1]\n",
        "tests = [data1_test,data2_test,data2_test,data1_test]\n",
        "\n",
        "model_doubleip.fit(trains, df_train['label'].values,batch_size=BATCH_SIZE, epochs=EPOCHS,validation_data=(tests,df_test['label'].values))\n",
        "print(roc_auc_score(df_test['label'].values, model_doubleip.predict(tests)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "49/49 [==============================] - 11s 194ms/step - loss: 0.6891 - accuracy: 0.5708 - val_loss: 0.6066 - val_accuracy: 0.6750\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 9s 187ms/step - loss: 0.6291 - accuracy: 0.6538 - val_loss: 0.6018 - val_accuracy: 0.6783\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 9s 188ms/step - loss: 0.5981 - accuracy: 0.6796 - val_loss: 0.5618 - val_accuracy: 0.7133\n",
            "Epoch 4/10\n",
            "49/49 [==============================] - 9s 186ms/step - loss: 0.5653 - accuracy: 0.7242 - val_loss: 0.5172 - val_accuracy: 0.7457\n",
            "Epoch 5/10\n",
            "49/49 [==============================] - 9s 188ms/step - loss: 0.4809 - accuracy: 0.7845 - val_loss: 0.4734 - val_accuracy: 0.7787\n",
            "Epoch 6/10\n",
            "49/49 [==============================] - 9s 186ms/step - loss: 0.3568 - accuracy: 0.8482 - val_loss: 0.4481 - val_accuracy: 0.8025\n",
            "Epoch 7/10\n",
            "49/49 [==============================] - 9s 187ms/step - loss: 0.2568 - accuracy: 0.8912 - val_loss: 0.5789 - val_accuracy: 0.7814\n",
            "Epoch 8/10\n",
            "49/49 [==============================] - 9s 187ms/step - loss: 0.1706 - accuracy: 0.9311 - val_loss: 0.5305 - val_accuracy: 0.8137\n",
            "Epoch 9/10\n",
            "49/49 [==============================] - 9s 187ms/step - loss: 0.1212 - accuracy: 0.9553 - val_loss: 0.6342 - val_accuracy: 0.8098\n",
            "Epoch 10/10\n",
            "49/49 [==============================] - 9s 187ms/step - loss: 0.0855 - accuracy: 0.9676 - val_loss: 0.7072 - val_accuracy: 0.8144\n",
            "0.8893951477098818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "xms8Vz_1lIv8",
        "outputId": "04f4bf28-2c32-455b-9fb5-4d552609a85d"
      },
      "source": [
        "df_train,df_test = load_data(5)\n",
        "print('The data used will be:')\n",
        "df_train[['Human','Yersinia']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The data used will be:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Human</th>\n",
              "      <th>Yersinia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[MKDKQ, KDKQK, DKQKK, KQKKK, QKKKK, KKKKE, KKK...</td>\n",
              "      <td>[MAKAS, AKASR, KASRH, ASRHN, SRHNL, RHNLS, HNL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[MSWSG, SWSGL, WSGLL, SGLLH, GLLHG, LLHGL, LHG...</td>\n",
              "      <td>[MQHVT, QHVTG, HVTGS, VTGSK, TGSKR, GSKRR, SKR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[MSLFD, SLFDL, LFDLF, FDLFR, DLFRG, LFRGF, FRG...</td>\n",
              "      <td>[MAELP, AELPA, ELPAK, LPAKR, PAKRR, AKRRF, KRR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[MAVAP, AVAPR, VAPRL, APRLF, PRLFG, RLFGG, LFG...</td>\n",
              "      <td>[MRIFA, RIFAI, IFAIS, FAISC, AISCS, ISCSS, SCS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[MSTIQ, STIQS, TIQSE, IQSET, QSETD, SETDC, ETD...</td>\n",
              "      <td>[MSYAF, SYAFP, YAFPG, AFPGT, FPGTF, PGTFP, GTF...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6265</th>\n",
              "      <td>[MSYFG, SYFGE, YFGEH, FGEHF, GEHFW, EHFWG, HFW...</td>\n",
              "      <td>[MITTD, ITTDG, TTDGN, TDGNS, DGNSA, GNSAV, NSA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6266</th>\n",
              "      <td>[MTVGK, TVGKS, VGKSS, GKSSK, KSSKM, SSKML, SKM...</td>\n",
              "      <td>[MSQPP, SQPPF, QPPFW, PPFWQ, PFWQQ, FWQQK, WQQ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6267</th>\n",
              "      <td>[MNNLS, NNLSF, NLSFS, LSFSE, SFSEL, FSELC, SEL...</td>\n",
              "      <td>[MSEDR, SEDRH, EDRHQ, DRHQQ, RHQQR, HQQRQ, QQR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6268</th>\n",
              "      <td>[MAPEI, APEIN, PEINL, EINLP, INLPG, NLPGP, LPG...</td>\n",
              "      <td>[MKNLS, KNLSF, NLSFV, LSFVA, SFVAG, FVAGL, VAG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6269</th>\n",
              "      <td>[MMLGT, MLGTE, LGTEG, GTEGG, TEGGE, EGGEG, GGE...</td>\n",
              "      <td>[MVMKK, VMKKI, MKKIA, KKIAC, KIACL, IACLS, ACL...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6270 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Human                                           Yersinia\n",
              "0     [MKDKQ, KDKQK, DKQKK, KQKKK, QKKKK, KKKKE, KKK...  [MAKAS, AKASR, KASRH, ASRHN, SRHNL, RHNLS, HNL...\n",
              "1     [MSWSG, SWSGL, WSGLL, SGLLH, GLLHG, LLHGL, LHG...  [MQHVT, QHVTG, HVTGS, VTGSK, TGSKR, GSKRR, SKR...\n",
              "2     [MSLFD, SLFDL, LFDLF, FDLFR, DLFRG, LFRGF, FRG...  [MAELP, AELPA, ELPAK, LPAKR, PAKRR, AKRRF, KRR...\n",
              "3     [MAVAP, AVAPR, VAPRL, APRLF, PRLFG, RLFGG, LFG...  [MRIFA, RIFAI, IFAIS, FAISC, AISCS, ISCSS, SCS...\n",
              "4     [MSTIQ, STIQS, TIQSE, IQSET, QSETD, SETDC, ETD...  [MSYAF, SYAFP, YAFPG, AFPGT, FPGTF, PGTFP, GTF...\n",
              "...                                                 ...                                                ...\n",
              "6265  [MSYFG, SYFGE, YFGEH, FGEHF, GEHFW, EHFWG, HFW...  [MITTD, ITTDG, TTDGN, TDGNS, DGNSA, GNSAV, NSA...\n",
              "6266  [MTVGK, TVGKS, VGKSS, GKSSK, KSSKM, SSKML, SKM...  [MSQPP, SQPPF, QPPFW, PPFWQ, PFWQQ, FWQQK, WQQ...\n",
              "6267  [MNNLS, NNLSF, NLSFS, LSFSE, SFSEL, FSELC, SEL...  [MSEDR, SEDRH, EDRHQ, DRHQQ, RHQQR, HQQRQ, QQR...\n",
              "6268  [MAPEI, APEIN, PEINL, EINLP, INLPG, NLPGP, LPG...  [MKNLS, KNLSF, NLSFV, LSFVA, SFVAG, FVAGL, VAG...\n",
              "6269  [MMLGT, MLGTE, LGTEG, GTEGG, TEGGE, EGGEG, GGE...  [MVMKK, VMKKI, MKKIA, KKIAC, KIACL, IACLS, ACL...\n",
              "\n",
              "[6270 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfyrmurylNBc",
        "outputId": "bcad4001-cf3c-446c-a3e4-fd8fcafad8e1"
      },
      "source": [
        " data1,data2,data1_test,data2_test,num_words,MAX_SEQUENCE_LENGTH,MAX_VOCAB_SIZE = f.get_seq_data_doubleip(500000,1000,df_train,df_test,pad = 'pre')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAX_VOCAB_SIZE is 500000\n",
            "MAX_SEQUENCE_LENGTH is 1000\n",
            "max sequences1_train length: 5301\n",
            "min sequences1_train length: 12\n",
            "median sequences1_train length: 327\n",
            "max word index sequences1_train: 499999\n",
            "max sequences2_train length: 3706\n",
            "min sequences2_train length: 9\n",
            "median sequences2_train length: 307\n",
            "max word index sequences2_train: 499999\n",
            "Found 1330540 unique tokens in tokenizer1.\n",
            "Found 639136 unique tokens in tokenizer2.\n",
            "pre padding\n",
            "Shape of data1 tensor: (6270, 1000)\n",
            "Shape of data2 tensor: (6270, 1000)\n",
            "max test_sequences1 length: 4674\n",
            "min test_sequences1 length: 10\n",
            "median test_sequences1 length: 271\n",
            "max test_sequences2 length: 3706\n",
            "min test_sequences2 length: 5\n",
            "median test_sequences2 length: 244\n",
            "pre padding for test seq.\n",
            "Shape of test_data1 tensor: (1514, 1000)\n",
            "Shape of test_data2 tensor: (1514, 1000)\n",
            "num_words is 500000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIJHdjzNlgD0",
        "outputId": "b6a4e97b-2939-4364-bfc5-4c4e0faa1327"
      },
      "source": [
        "EMBEDDING_DIM = 15\n",
        "VALIDATION_SPLIT = 0.2\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "M_1D=10\n",
        "DROP = 0.8\n",
        "\n",
        "ip1 = f.att_model(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM,num_words,DROP)\n",
        "ip2 = f.att_model(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM,num_words,DROP)\n",
        "\n",
        "concatenator = Concatenate(axis=1)\n",
        "x = concatenator([ip1.output, ip2.output])\n",
        "x = Dense(128)(x)\n",
        "#x = concatenator([x1.output, x2.output]) # output is N x 4M\n",
        "#x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(DROP)(x)\n",
        "output = Dense(1, activation=\"sigmoid\",name=\"Final\")(x)\n",
        "model_doubleip = Model(inputs=[ip1.input,ip2.input], outputs=output)\n",
        "#plot_model(model1D_CNN_doubleip, to_file='model_plot.png', show_shapes=True, show_layer_names=False)\n",
        "model_doubleip.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "trains = [data1,data2,data2,data1]\n",
        "tests = [data1_test,data2_test,data2_test,data1_test]\n",
        "\n",
        "model_doubleip.fit(trains, df_train['label'].values,batch_size=BATCH_SIZE, epochs=EPOCHS,validation_data=(tests,df_test['label'].values))\n",
        "print(roc_auc_score(df_test['label'].values, model_doubleip.predict(tests)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "49/49 [==============================] - 21s 380ms/step - loss: 0.7634 - accuracy: 0.5560 - val_loss: 0.6109 - val_accuracy: 0.6374\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 18s 371ms/step - loss: 0.6032 - accuracy: 0.6875 - val_loss: 0.5980 - val_accuracy: 0.6863\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 18s 374ms/step - loss: 0.5850 - accuracy: 0.7035 - val_loss: 0.5966 - val_accuracy: 0.6625\n",
            "Epoch 4/10\n",
            "49/49 [==============================] - 18s 372ms/step - loss: 0.5568 - accuracy: 0.7032 - val_loss: 0.5628 - val_accuracy: 0.7318\n",
            "Epoch 5/10\n",
            "49/49 [==============================] - 18s 368ms/step - loss: 0.5116 - accuracy: 0.7523 - val_loss: 0.5158 - val_accuracy: 0.7748\n",
            "Epoch 6/10\n",
            "49/49 [==============================] - 18s 375ms/step - loss: 0.4059 - accuracy: 0.8288 - val_loss: 0.4616 - val_accuracy: 0.8091\n",
            "Epoch 7/10\n",
            "49/49 [==============================] - 18s 370ms/step - loss: 0.3147 - accuracy: 0.8720 - val_loss: 0.5306 - val_accuracy: 0.7985\n",
            "Epoch 8/10\n",
            "49/49 [==============================] - 18s 369ms/step - loss: 0.2158 - accuracy: 0.9173 - val_loss: 0.4859 - val_accuracy: 0.8078\n",
            "Epoch 9/10\n",
            "49/49 [==============================] - 18s 372ms/step - loss: 0.1291 - accuracy: 0.9500 - val_loss: 0.4938 - val_accuracy: 0.8104\n",
            "Epoch 10/10\n",
            "49/49 [==============================] - 18s 368ms/step - loss: 0.0922 - accuracy: 0.9670 - val_loss: 0.5756 - val_accuracy: 0.8091\n",
            "0.8984205539142377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "BZZEL8Ci8VCV",
        "outputId": "8c12662f-b9c8-47e4-f7d7-93aba07eac97"
      },
      "source": [
        "df_train,df_test = load_data(6)\n",
        "print('The data used will be:')\n",
        "df_train[['Human','Yersinia']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The data used will be:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Human</th>\n",
              "      <th>Yersinia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[MKDKQK, KDKQKK, DKQKKK, KQKKKK, QKKKKE, KKKKE...</td>\n",
              "      <td>[MAKASR, AKASRH, KASRHN, ASRHNL, SRHNLS, RHNLS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[MSWSGL, SWSGLL, WSGLLH, SGLLHG, GLLHGL, LLHGL...</td>\n",
              "      <td>[MQHVTG, QHVTGS, HVTGSK, VTGSKR, TGSKRR, GSKRR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[MSLFDL, SLFDLF, LFDLFR, FDLFRG, DLFRGF, LFRGF...</td>\n",
              "      <td>[MAELPA, AELPAK, ELPAKR, LPAKRR, PAKRRF, AKRRF...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[MAVAPR, AVAPRL, VAPRLF, APRLFG, PRLFGG, RLFGG...</td>\n",
              "      <td>[MRIFAI, RIFAIS, IFAISC, FAISCS, AISCSS, ISCSS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[MSTIQS, STIQSE, TIQSET, IQSETD, QSETDC, SETDC...</td>\n",
              "      <td>[MSYAFP, SYAFPG, YAFPGT, AFPGTF, FPGTFP, PGTFP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6265</th>\n",
              "      <td>[MSYFGE, SYFGEH, YFGEHF, FGEHFW, GEHFWG, EHFWG...</td>\n",
              "      <td>[MITTDG, ITTDGN, TTDGNS, TDGNSA, DGNSAV, GNSAV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6266</th>\n",
              "      <td>[MTVGKS, TVGKSS, VGKSSK, GKSSKM, KSSKML, SSKML...</td>\n",
              "      <td>[MSQPPF, SQPPFW, QPPFWQ, PPFWQQ, PFWQQK, FWQQK...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6267</th>\n",
              "      <td>[MNNLSF, NNLSFS, NLSFSE, LSFSEL, SFSELC, FSELC...</td>\n",
              "      <td>[MSEDRH, SEDRHQ, EDRHQQ, DRHQQR, RHQQRQ, HQQRQ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6268</th>\n",
              "      <td>[MAPEIN, APEINL, PEINLP, EINLPG, INLPGP, NLPGP...</td>\n",
              "      <td>[MKNLSF, KNLSFV, NLSFVA, LSFVAG, SFVAGL, FVAGL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6269</th>\n",
              "      <td>[MMLGTE, MLGTEG, LGTEGG, GTEGGE, TEGGEG, EGGEG...</td>\n",
              "      <td>[MVMKKI, VMKKIA, MKKIAC, KKIACL, KIACLS, IACLS...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6270 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Human                                           Yersinia\n",
              "0     [MKDKQK, KDKQKK, DKQKKK, KQKKKK, QKKKKE, KKKKE...  [MAKASR, AKASRH, KASRHN, ASRHNL, SRHNLS, RHNLS...\n",
              "1     [MSWSGL, SWSGLL, WSGLLH, SGLLHG, GLLHGL, LLHGL...  [MQHVTG, QHVTGS, HVTGSK, VTGSKR, TGSKRR, GSKRR...\n",
              "2     [MSLFDL, SLFDLF, LFDLFR, FDLFRG, DLFRGF, LFRGF...  [MAELPA, AELPAK, ELPAKR, LPAKRR, PAKRRF, AKRRF...\n",
              "3     [MAVAPR, AVAPRL, VAPRLF, APRLFG, PRLFGG, RLFGG...  [MRIFAI, RIFAIS, IFAISC, FAISCS, AISCSS, ISCSS...\n",
              "4     [MSTIQS, STIQSE, TIQSET, IQSETD, QSETDC, SETDC...  [MSYAFP, SYAFPG, YAFPGT, AFPGTF, FPGTFP, PGTFP...\n",
              "...                                                 ...                                                ...\n",
              "6265  [MSYFGE, SYFGEH, YFGEHF, FGEHFW, GEHFWG, EHFWG...  [MITTDG, ITTDGN, TTDGNS, TDGNSA, DGNSAV, GNSAV...\n",
              "6266  [MTVGKS, TVGKSS, VGKSSK, GKSSKM, KSSKML, SSKML...  [MSQPPF, SQPPFW, QPPFWQ, PPFWQQ, PFWQQK, FWQQK...\n",
              "6267  [MNNLSF, NNLSFS, NLSFSE, LSFSEL, SFSELC, FSELC...  [MSEDRH, SEDRHQ, EDRHQQ, DRHQQR, RHQQRQ, HQQRQ...\n",
              "6268  [MAPEIN, APEINL, PEINLP, EINLPG, INLPGP, NLPGP...  [MKNLSF, KNLSFV, NLSFVA, LSFVAG, SFVAGL, FVAGL...\n",
              "6269  [MMLGTE, MLGTEG, LGTEGG, GTEGGE, TEGGEG, EGGEG...  [MVMKKI, VMKKIA, MKKIAC, KKIACL, KIACLS, IACLS...\n",
              "\n",
              "[6270 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JKPZlpt8XV8",
        "outputId": "87d49ba0-e123-4a21-da85-060f2ee6acd0"
      },
      "source": [
        " data1,data2,data1_test,data2_test,num_words,MAX_SEQUENCE_LENGTH,MAX_VOCAB_SIZE = f.get_seq_data_doubleip(850000,1000,df_train,df_test,pad = 'pre')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAX_VOCAB_SIZE is 850000\n",
            "MAX_SEQUENCE_LENGTH is 1000\n",
            "max sequences1_train length: 5630\n",
            "min sequences1_train length: 0\n",
            "median sequences1_train length: 199\n",
            "max word index sequences1_train: 849999\n",
            "max sequences2_train length: 3705\n",
            "min sequences2_train length: 0\n",
            "median sequences2_train length: 329\n",
            "max word index sequences2_train: 849999\n",
            "Found 2438322 unique tokens in tokenizer1.\n",
            "Found 864366 unique tokens in tokenizer2.\n",
            "pre padding\n",
            "Shape of data1 tensor: (6270, 1000)\n",
            "Shape of data2 tensor: (6270, 1000)\n",
            "max test_sequences1 length: 5630\n",
            "min test_sequences1 length: 0\n",
            "median test_sequences1 length: 70\n",
            "max test_sequences2 length: 3705\n",
            "min test_sequences2 length: 0\n",
            "median test_sequences2 length: 284\n",
            "pre padding for test seq.\n",
            "Shape of test_data1 tensor: (1514, 1000)\n",
            "Shape of test_data2 tensor: (1514, 1000)\n",
            "num_words is 850000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh8Jyn-o8fzF",
        "outputId": "18904746-8b10-44aa-bbdc-f6a05cfaed63"
      },
      "source": [
        "EMBEDDING_DIM = 15\n",
        "VALIDATION_SPLIT = 0.2\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "M_1D=10\n",
        "DROP = 0.8\n",
        "\n",
        "ip1 = f.att_model(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM,num_words,DROP)\n",
        "ip2 = f.att_model(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM,num_words,DROP)\n",
        "\n",
        "concatenator = Concatenate(axis=1)\n",
        "x = concatenator([ip1.output, ip2.output])\n",
        "x = Dense(128)(x)\n",
        "#x = concatenator([x1.output, x2.output]) # output is N x 4M\n",
        "#x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(DROP)(x)\n",
        "output = Dense(1, activation=\"sigmoid\",name=\"Final\")(x)\n",
        "model_doubleip = Model(inputs=[ip1.input,ip2.input], outputs=output)\n",
        "#plot_model(model1D_CNN_doubleip, to_file='model_plot.png', show_shapes=True, show_layer_names=False)\n",
        "model_doubleip.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "trains = [data1,data2,data2,data1]\n",
        "tests = [data1_test,data2_test,data2_test,data1_test]\n",
        "\n",
        "model_doubleip.fit(trains, df_train['label'].values,batch_size=BATCH_SIZE, epochs=EPOCHS,validation_data=(tests,df_test['label'].values))\n",
        "print(roc_auc_score(df_test['label'].values, model_doubleip.predict(tests)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "49/49 [==============================] - 30s 583ms/step - loss: 0.7745 - accuracy: 0.5410 - val_loss: 0.5858 - val_accuracy: 0.7127\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 28s 577ms/step - loss: 0.6023 - accuracy: 0.6970 - val_loss: 0.5743 - val_accuracy: 0.7147\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 28s 576ms/step - loss: 0.5618 - accuracy: 0.7210 - val_loss: 0.5592 - val_accuracy: 0.7001\n",
            "Epoch 4/10\n",
            "49/49 [==============================] - 28s 578ms/step - loss: 0.5259 - accuracy: 0.7428 - val_loss: 0.6001 - val_accuracy: 0.6546\n",
            "Epoch 5/10\n",
            "49/49 [==============================] - 28s 579ms/step - loss: 0.4505 - accuracy: 0.7969 - val_loss: 0.5512 - val_accuracy: 0.7450\n",
            "Epoch 6/10\n",
            "49/49 [==============================] - 28s 576ms/step - loss: 0.3661 - accuracy: 0.8502 - val_loss: 0.6475 - val_accuracy: 0.7483\n",
            "Epoch 7/10\n",
            "49/49 [==============================] - 28s 574ms/step - loss: 0.2659 - accuracy: 0.8862 - val_loss: 0.7011 - val_accuracy: 0.7734\n",
            "Epoch 8/10\n",
            "49/49 [==============================] - 28s 575ms/step - loss: 0.1886 - accuracy: 0.9270 - val_loss: 0.6562 - val_accuracy: 0.7913\n",
            "Epoch 9/10\n",
            "49/49 [==============================] - 28s 576ms/step - loss: 0.1478 - accuracy: 0.9420 - val_loss: 0.7944 - val_accuracy: 0.7807\n",
            "Epoch 10/10\n",
            "49/49 [==============================] - 28s 576ms/step - loss: 0.1101 - accuracy: 0.9607 - val_loss: 0.8824 - val_accuracy: 0.7840\n",
            "0.8988603068847515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am_T6NRgN89I"
      },
      "source": [
        "#### We will try for 5D with 3X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLLDe0ppH3q5",
        "outputId": "c18dfd9b-be3c-41d8-8296-e1f4ea1047f9"
      },
      "source": [
        "data1_5D_doubleip_pre,data2_5D_doubleip_pre,data1_test_5D_doubleip_pre,data2_test_5D_doubleip_pre,num_words_5D,MAX_SEQUENCE_LENGTH_5D,MAX_VOCAB_SIZE_5D = f.get_seq_data_doubleip(500000,1000,df_train,df_test,pad = 'pre')\n",
        "data1_5D_doubleip_center,data2_5D_doubleip_center,data1_test_5D_doubleip_center,data2_test_5D_doubleip_center,num_words_5D,MAX_SEQUENCE_LENGTH_5D,MAX_VOCAB_SIZE_5D = f.get_seq_data_doubleip(500000,1000,df_train,df_test)\n",
        "data1_5D_doubleip_post,data2_5D_doubleip_post,data1_test_5D_doubleip_post,data2_test_5D_doubleip_post,num_words_5D,MAX_SEQUENCE_LENGTH_5D,MAX_VOCAB_SIZE_5D = f.get_seq_data_doubleip(500000,1000,df_train,df_test,pad = 'post')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAX_VOCAB_SIZE is 500000\n",
            "MAX_SEQUENCE_LENGTH is 1000\n",
            "max sequences1_train length: 5301\n",
            "min sequences1_train length: 12\n",
            "median sequences1_train length: 327\n",
            "max word index sequences1_train: 499999\n",
            "max sequences2_train length: 3706\n",
            "min sequences2_train length: 9\n",
            "median sequences2_train length: 307\n",
            "max word index sequences2_train: 499999\n",
            "Found 1330540 unique tokens in tokenizer1.\n",
            "Found 639136 unique tokens in tokenizer2.\n",
            "pre padding\n",
            "Shape of data1 tensor: (6270, 1000)\n",
            "Shape of data2 tensor: (6270, 1000)\n",
            "max test_sequences1 length: 4674\n",
            "min test_sequences1 length: 10\n",
            "median test_sequences1 length: 271\n",
            "max test_sequences2 length: 3706\n",
            "min test_sequences2 length: 5\n",
            "median test_sequences2 length: 244\n",
            "pre padding for test seq.\n",
            "Shape of test_data1 tensor: (1514, 1000)\n",
            "Shape of test_data2 tensor: (1514, 1000)\n",
            "num_words is 500000\n",
            "MAX_VOCAB_SIZE is 500000\n",
            "MAX_SEQUENCE_LENGTH is 1000\n",
            "max sequences1_train length: 5301\n",
            "min sequences1_train length: 12\n",
            "median sequences1_train length: 327\n",
            "max word index sequences1_train: 499999\n",
            "max sequences2_train length: 3706\n",
            "min sequences2_train length: 9\n",
            "median sequences2_train length: 307\n",
            "max word index sequences2_train: 499999\n",
            "Found 1330540 unique tokens in tokenizer1.\n",
            "Found 639136 unique tokens in tokenizer2.\n",
            "Center padding\n",
            "Shape of data1 tensor: (6270, 1000)\n",
            "Shape of data2 tensor: (6270, 1000)\n",
            "max test_sequences1 length: 4674\n",
            "min test_sequences1 length: 10\n",
            "median test_sequences1 length: 271\n",
            "max test_sequences2 length: 3706\n",
            "min test_sequences2 length: 5\n",
            "median test_sequences2 length: 244\n",
            "Center padding for test seq.\n",
            "Shape of test_data1 tensor: (1514, 1000)\n",
            "Shape of test_data2 tensor: (1514, 1000)\n",
            "num_words is 500000\n",
            "MAX_VOCAB_SIZE is 500000\n",
            "MAX_SEQUENCE_LENGTH is 1000\n",
            "max sequences1_train length: 5301\n",
            "min sequences1_train length: 12\n",
            "median sequences1_train length: 327\n",
            "max word index sequences1_train: 499999\n",
            "max sequences2_train length: 3706\n",
            "min sequences2_train length: 9\n",
            "median sequences2_train length: 307\n",
            "max word index sequences2_train: 499999\n",
            "Found 1330540 unique tokens in tokenizer1.\n",
            "Found 639136 unique tokens in tokenizer2.\n",
            "post padding\n",
            "Shape of data1 tensor: (6270, 1000)\n",
            "Shape of data2 tensor: (6270, 1000)\n",
            "max test_sequences1 length: 4674\n",
            "min test_sequences1 length: 10\n",
            "median test_sequences1 length: 271\n",
            "max test_sequences2 length: 3706\n",
            "min test_sequences2 length: 5\n",
            "median test_sequences2 length: 244\n",
            "post padding for test seq.\n",
            "Shape of test_data1 tensor: (1514, 1000)\n",
            "Shape of test_data2 tensor: (1514, 1000)\n",
            "num_words is 500000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCDxC5lNINtG",
        "outputId": "6a6a7862-50a5-413e-e002-0af812f311e6"
      },
      "source": [
        "\n",
        "\n",
        "EMBEDDING_DIM_5D = 15\n",
        "VALIDATION_SPLIT = 0.2\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "DROP=0.8\n",
        "\n",
        "x1 = f.att_model(MAX_SEQUENCE_LENGTH_5D,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x2 = f.att_model(MAX_SEQUENCE_LENGTH_5D,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x3 = f.att_model(MAX_SEQUENCE_LENGTH_5D,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x4 = f.att_model(MAX_SEQUENCE_LENGTH_5D,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x5 = f.att_model(MAX_SEQUENCE_LENGTH_5D,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x6 = f.att_model(MAX_SEQUENCE_LENGTH_5D,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "\n",
        "concatenator = Concatenate(axis=1)\n",
        "x = concatenator([x1.output, x2.output, x3.output, x4.output, x5.output, x6.output])\n",
        "x = Dense(128)(x)\n",
        "x = Dropout(DROP)(x)\n",
        "output = Dense(1, activation=\"sigmoid\",name=\"Final\")(x)\n",
        "model5D_CNN_doubleip = Model(inputs=[x1.input, x2.input, x3.input, x4.input, x5.input, x6.input], outputs=output)\n",
        "\n",
        "model5D_CNN_doubleip.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#plot_model(model5D_CNN_doubleip, to_file='model_plot.png', show_shapes=True, show_layer_names=False)\n",
        "\n",
        "trains = [data1_5D_doubleip_pre,data2_5D_doubleip_pre,data2_5D_doubleip_pre,data1_5D_doubleip_pre,data1_5D_doubleip_center,data2_5D_doubleip_center,data2_5D_doubleip_center,data1_5D_doubleip_center,data1_5D_doubleip_post,data2_5D_doubleip_post,data2_5D_doubleip_post,data1_5D_doubleip_post]\n",
        "tests = [data1_test_5D_doubleip_pre,data2_test_5D_doubleip_pre,data2_test_5D_doubleip_pre,data1_test_5D_doubleip_pre,data1_test_5D_doubleip_center,data2_test_5D_doubleip_center,data2_test_5D_doubleip_center,data1_test_5D_doubleip_center,data1_test_5D_doubleip_post,data2_test_5D_doubleip_post,data2_test_5D_doubleip_post,data1_test_5D_doubleip_post]\n",
        "\n",
        "\n",
        "model5D_CNN_doubleip.fit(trains, df_train['label'].values, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(tests, df_test['label'].values))\n",
        "print(roc_auc_score(df_test['label'].values, model5D_CNN_doubleip.predict(tests)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "49/49 [==============================] - 57s 1s/step - loss: 0.8022 - accuracy: 0.5722 - val_loss: 0.5891 - val_accuracy: 0.6968\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 51s 1s/step - loss: 0.6088 - accuracy: 0.6889 - val_loss: 0.6040 - val_accuracy: 0.6367\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 50s 1s/step - loss: 0.5875 - accuracy: 0.6931 - val_loss: 0.5815 - val_accuracy: 0.6691\n",
            "Epoch 4/10\n",
            "49/49 [==============================] - 50s 1s/step - loss: 0.5452 - accuracy: 0.7273 - val_loss: 0.5580 - val_accuracy: 0.6724\n",
            "Epoch 5/10\n",
            "49/49 [==============================] - 51s 1s/step - loss: 0.4400 - accuracy: 0.7984 - val_loss: 0.4497 - val_accuracy: 0.7807\n",
            "Epoch 6/10\n",
            "49/49 [==============================] - 50s 1s/step - loss: 0.2815 - accuracy: 0.8844 - val_loss: 0.4555 - val_accuracy: 0.7952\n",
            "Epoch 7/10\n",
            "49/49 [==============================] - 50s 1s/step - loss: 0.1584 - accuracy: 0.9460 - val_loss: 0.4733 - val_accuracy: 0.8052\n",
            "Epoch 8/10\n",
            "49/49 [==============================] - 50s 1s/step - loss: 0.0923 - accuracy: 0.9683 - val_loss: 0.5364 - val_accuracy: 0.8177\n",
            "Epoch 9/10\n",
            "49/49 [==============================] - 50s 1s/step - loss: 0.0526 - accuracy: 0.9843 - val_loss: 0.5802 - val_accuracy: 0.8184\n",
            "Epoch 10/10\n",
            "49/49 [==============================] - 49s 1s/step - loss: 0.0456 - accuracy: 0.9866 - val_loss: 0.6396 - val_accuracy: 0.8164\n",
            "0.8998855246235489\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}