{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hv_final_model_three_groups.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1LKZgcvvpYvvSG_d93w44jhHxq2q-IhdW",
      "authorship_tag": "ABX9TyOg4IbKDRpEshHkFMg2j3C8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhil-mathews/MastersPr_Predicting-Human-Pathogen-PPIs-using-Natural-Language-Processing-methods/blob/main/4.Final_model/hv_final_model_three_groups.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JfulEV-Ct76"
      },
      "source": [
        "## Each train-test group in the source data are used to train and test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDfJD8MItdQh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76bcfcd0-2589-4a0e-d9f9-dd259ae5c636"
      },
      "source": [
        "import pandas as pd\n",
        "#Google colab does not have pickle\n",
        "try:\n",
        "  import pickle5 as pickle\n",
        "except:\n",
        "  !pip install pickle5\n",
        "  import pickle5 as pickle\n",
        "import os\n",
        "import seaborn as sns\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D,Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding,Concatenate\n",
        "from keras.models import Model,load_model\n",
        "from sklearn.metrics import roc_auc_score,confusion_matrix,roc_curve, auc\n",
        "from numpy import random\n",
        "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.metrics import AUC\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/ML_Data/')\n",
        "import functions as f\n",
        "\n",
        "directory = '/content/drive/MyDrive/ML_Data/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pickle5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/4c/5c4dd0462c8d3a6bc4af500a6af240763c2ebd1efdc736fc2c946d44b70a/pickle5-0.0.11.tar.gz (132kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 25.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 32.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30kB 22.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 17.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 51kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 61kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 71kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 81kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 92kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 102kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 112kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 122kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 14.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp37-cp37m-linux_x86_64.whl size=219265 sha256=ebaa852fffe7b30b24a7047ad0d6c61edcc98bac173f7490a9719f7731a65089\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/90/95/f889ca4aa8b0e0c7f21c8470b6f5d6032f0390a3a141a9a3bd\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTqhCtJVgZDB"
      },
      "source": [
        "def load(name):\n",
        "    try:\n",
        "        with open(directory+''+name+'.pickle', 'rb') as handle:\n",
        "            return pickle.load(handle)\n",
        "    except:\n",
        "        with open(directory+''+name+'.pkl', 'rb') as handle:\n",
        "            return pickle.load(handle)\n",
        "\n",
        "\n",
        "def to_HYPPI(df):\n",
        "  df = df.rename(columns={'Virus':'Yersinia'})\n",
        "  df[\"Joined\"] = [df.loc[row]['Human']+df.loc[row]['Yersinia'] for row in range(df.shape[0])]\n",
        "  return df\n",
        "\n",
        "#load('HVindependent_test_group1')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPefryYQdxKo"
      },
      "source": [
        "### Test train Gp1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eqXHPuyZ2AQ",
        "outputId": "33e73cb9-411e-44d8-c8aa-1740a684c91e"
      },
      "source": [
        "'''Convert to a format acceptable to the model'''\n",
        "dftest_1D = to_HYPPI(load('HVindependent_test_group1').reset_index(drop=True))\n",
        "dftrain_1D = to_HYPPI(load('HVtrain_set_group1').reset_index(drop=True))\n",
        "dftrain_1D.shape,dftest_1D.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((179971, 4), (45078, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vgX6BK5bGEg",
        "outputId": "edba5aa0-1cf1-4e43-d73c-f3e539e66098"
      },
      "source": [
        "# f.save(dftrain_1D,'HV_train_1D')\n",
        "# f.save(dftest_1D,'HV_test_1D')\n",
        "df_train = f.load('HV_train_1D')\n",
        "\n",
        "multiple = df_train.shape[0]//20\n",
        "\n",
        "\"\"\"\n",
        "not perfect. one datapoint is repeated across each subset, and some are lost.\n",
        "but considering the overall size, impact of this on result is zero\n",
        "\"\"\"\n",
        "\n",
        "for i in range(20):\n",
        "  print(i+1)\n",
        "  df = df_train.loc[multiple*i:multiple*(i+1)].reset_index(drop=True)\n",
        "  f.combine_AC(df,5)\n",
        "  f.save(df,'HV_train_'+str(i)+'')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y86YplJbyNz",
        "outputId": "cd5c3f0b-2865-4bd9-d98c-67d712c01583"
      },
      "source": [
        "train_5D = f.load('HV_train_0')\n",
        "for i in range(1,20):\n",
        "  train_5D = pd.concat([train_5D,f.load('HV_train_'+str(i)+'')]).reset_index(drop=True)\n",
        "train_5D\n",
        "f.create_tokenizers(train_5D)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved tokenizers as doubleip_tkrs\n",
            "Saved tokenizer as join_tkr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SngPzm6fbyQo"
      },
      "source": [
        "df_test = f.load('HV_test_1D')\n",
        "f.combine_AC(df_test,5)\n",
        "#f.save(df_test,'HV_test_5D')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL8KbsCcbyTr",
        "outputId": "fa4263bc-d11b-41e4-f8c0-7469fd65aa94"
      },
      "source": [
        "df_test = f.load('HV_test_5D')\n",
        "tests = f.preprocess(df_test,saveTokrs=False)\n",
        "#f.save(tests,'tests')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JROu4CrAchF_"
      },
      "source": [
        "df_test_5D = f.load('HV_test_5D')\n",
        "val_tests = df_test_5D.loc[:1500]\n",
        "f.save(val_tests,'val_tests')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwWoQMhychJh",
        "outputId": "f55fd8c7-46c8-4ac9-e8d8-429ad316b351"
      },
      "source": [
        "EMBEDDING_DIM_5D = 50\n",
        "VALIDATION_SPLIT = 0.2\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 1\n",
        "DROP = 0.5\n",
        "threshold = 0.918\n",
        "MAX_SEQUENCE_LENGTH_5D_J = 2000\n",
        "MAX_SEQUENCE_LENGTH_5D_dIP = 1000\n",
        "num_words_5D_J = 1000000\n",
        "num_words_5D = 500000\n",
        "\n",
        "x1_join = f.transf_model(MAX_SEQUENCE_LENGTH_5D_J,num_words_5D_J,5,0.9)\n",
        "x2_join = f.transf_model(MAX_SEQUENCE_LENGTH_5D_J,num_words_5D_J,5,0.9)\n",
        "x3_join = f.transf_model(MAX_SEQUENCE_LENGTH_5D_J,num_words_5D_J,5,0.9)\n",
        "\n",
        "x1_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x2_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x3_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x4_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x5_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x6_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "\n",
        "concatenator = Concatenate(axis=1)\n",
        "x = concatenator([x1_join.output, x2_join.output, x3_join.output, x1_doubleip.output, x2_doubleip.output, x3_doubleip.output, x4_doubleip.output, x5_doubleip.output, x6_doubleip.output])\n",
        "x = Dense(256)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation=\"sigmoid\",name=\"Final\")(x)\n",
        "model_HV = Model(inputs=[x1_join.input, x2_join.input, x3_join.input, x1_doubleip.input, x2_doubleip.input, x3_doubleip.input, x4_doubleip.input, x5_doubleip.input, x6_doubleip.input], outputs=output)\n",
        "\n",
        "model_HV.compile(loss='binary_crossentropy', optimizer='adam', metrics=AUC())\n",
        "\n",
        "#model_HV.save(directory+'model_HV')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_2_layer_call_and_return_conditional_losses while saving (showing 5 of 195). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embedding_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_2_layer_call_and_return_conditional_losses while saving (showing 5 of 195). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_Data/model_HV/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_Data/model_HV/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRvCGD1IeDou"
      },
      "source": [
        "### 1st Epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9VOTdWedkv_",
        "outputId": "b1511805-8c82-43ff-fa53-01e07111dddb"
      },
      "source": [
        "df_test = f.load('val_tests')\n",
        "val_tests = f.preprocess(df_test,saveTokrs=False)\n",
        "model_HV = load_model(directory+'model_HV')\n",
        "names = ['HV_train_'+str(i) for i in range(20)]\n",
        "\n",
        "for name in names:\n",
        "  print(name)\n",
        "  df_train = f.load(name)\n",
        "  trains = f.preprocess(df_train,saveTokrs=False)\n",
        "  model_HV.fit(trains, df_train['Label'].values, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(val_tests,df_test['Label'].values))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing...\n",
            "HV_train_0\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 306s 1s/step - loss: 0.3063 - auc: 0.6779 - val_loss: 0.2249 - val_auc: 0.8431\n",
            "HV_train_1\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 281s 998ms/step - loss: 0.2396 - auc: 0.7972 - val_loss: 0.2090 - val_auc: 0.8639\n",
            "HV_train_2\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 280s 994ms/step - loss: 0.2174 - auc: 0.8415 - val_loss: 0.2039 - val_auc: 0.8775\n",
            "HV_train_3\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 281s 995ms/step - loss: 0.1943 - auc: 0.8865 - val_loss: 0.1724 - val_auc: 0.9078\n",
            "HV_train_4\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 283s 1s/step - loss: 0.1941 - auc: 0.8806 - val_loss: 0.1818 - val_auc: 0.9065\n",
            "HV_train_5\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 277s 984ms/step - loss: 0.2002 - auc: 0.8872 - val_loss: 0.1743 - val_auc: 0.9056\n",
            "HV_train_6\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 278s 986ms/step - loss: 0.1775 - auc: 0.9049 - val_loss: 0.1681 - val_auc: 0.9184\n",
            "HV_train_7\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 277s 984ms/step - loss: 0.1883 - auc: 0.8991 - val_loss: 0.1745 - val_auc: 0.9136\n",
            "HV_train_8\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 274s 971ms/step - loss: 0.1768 - auc: 0.9051 - val_loss: 0.1702 - val_auc: 0.9162\n",
            "HV_train_9\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 278s 986ms/step - loss: 0.1729 - auc: 0.9130 - val_loss: 0.1672 - val_auc: 0.9208\n",
            "HV_train_10\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 281s 996ms/step - loss: 0.1857 - auc: 0.9054 - val_loss: 0.1649 - val_auc: 0.9249\n",
            "HV_train_11\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 283s 1s/step - loss: 0.1654 - auc: 0.9269 - val_loss: 0.1610 - val_auc: 0.9228\n",
            "HV_train_12\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 282s 999ms/step - loss: 0.1740 - auc: 0.9144 - val_loss: 0.1688 - val_auc: 0.9252\n",
            "HV_train_13\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 282s 1000ms/step - loss: 0.1703 - auc: 0.9230 - val_loss: 0.1762 - val_auc: 0.9237\n",
            "HV_train_14\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 271s 961ms/step - loss: 0.1594 - auc: 0.9227 - val_loss: 0.1516 - val_auc: 0.9296\n",
            "HV_train_15\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 272s 963ms/step - loss: 0.1634 - auc: 0.9230 - val_loss: 0.1513 - val_auc: 0.9310\n",
            "HV_train_16\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 271s 961ms/step - loss: 0.1604 - auc: 0.9261 - val_loss: 0.1614 - val_auc: 0.9285\n",
            "HV_train_17\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 272s 964ms/step - loss: 0.1654 - auc: 0.9226 - val_loss: 0.1561 - val_auc: 0.9259\n",
            "HV_train_18\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 271s 961ms/step - loss: 0.1580 - auc: 0.9297 - val_loss: 0.1488 - val_auc: 0.9307\n",
            "HV_train_19\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 272s 964ms/step - loss: 0.1598 - auc: 0.9248 - val_loss: 0.1513 - val_auc: 0.9357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRcOZhPddky8",
        "outputId": "026f6ef2-00a7-4814-f48c-465f5443e1ec"
      },
      "source": [
        "#model_HV.save(directory+'model_HV')\n",
        "model_HV = load_model(directory+'model_HV')\n",
        "df_test = f.load('HV_test_5D')\n",
        "roc_auc_score(df_test['Label'].values, model_HV.predict(f.load('tests')))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_2_layer_call_and_return_conditional_losses while saving (showing 5 of 195). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embedding_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_2_layer_call_and_return_conditional_losses while saving (showing 5 of 195). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_Data/model_HV/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_Data/model_HV/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.93409074883795"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDQC-D33eJOg"
      },
      "source": [
        "### 2nd Epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9GAY5VnNCgF",
        "outputId": "88b271ab-3c33-4aa4-dbc5-739e50b651cd"
      },
      "source": [
        "df_test = f.load('val_tests')\n",
        "val_tests = f.preprocess(df_test,saveTokrs=False)\n",
        "model_HV = load_model(directory+'model_HV')\n",
        "names = ['HV_train_'+str(i) for i in range(20)]\n",
        "\n",
        "for name in names:\n",
        "  print(name)\n",
        "  df_train = f.load(name)\n",
        "  trains = f.preprocess(df_train,saveTokrs=False)\n",
        "  model_HV.fit(trains, df_train['Label'].values, epochs=1, batch_size=32, validation_data=(val_tests,df_test['Label'].values))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing...\n",
            "HV_train_0\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 248s 804ms/step - loss: 0.1493 - auc: 0.9439 - val_loss: 0.1474 - val_auc: 0.9405\n",
            "HV_train_1\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 223s 792ms/step - loss: 0.1407 - auc: 0.9440 - val_loss: 0.1563 - val_auc: 0.9268\n",
            "HV_train_2\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 224s 793ms/step - loss: 0.1446 - auc: 0.9409 - val_loss: 0.1499 - val_auc: 0.9370\n",
            "HV_train_3\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 222s 786ms/step - loss: 0.1310 - auc: 0.9545 - val_loss: 0.1554 - val_auc: 0.9322\n",
            "HV_train_4\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 221s 783ms/step - loss: 0.1337 - auc: 0.9522 - val_loss: 0.1525 - val_auc: 0.9326\n",
            "HV_train_5\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 222s 786ms/step - loss: 0.1434 - auc: 0.9503 - val_loss: 0.1550 - val_auc: 0.9311\n",
            "HV_train_6\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 218s 773ms/step - loss: 0.1271 - auc: 0.9605 - val_loss: 0.1604 - val_auc: 0.9235\n",
            "HV_train_7\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 219s 777ms/step - loss: 0.1378 - auc: 0.9521 - val_loss: 0.1513 - val_auc: 0.9292\n",
            "HV_train_8\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 221s 782ms/step - loss: 0.1327 - auc: 0.9516 - val_loss: 0.1459 - val_auc: 0.9381\n",
            "HV_train_9\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 220s 780ms/step - loss: 0.1289 - auc: 0.9566 - val_loss: 0.1483 - val_auc: 0.9346\n",
            "HV_train_10\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 216s 766ms/step - loss: 0.1484 - auc: 0.9437 - val_loss: 0.1640 - val_auc: 0.9339\n",
            "HV_train_11\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 219s 776ms/step - loss: 0.1282 - auc: 0.9616 - val_loss: 0.1501 - val_auc: 0.9320\n",
            "HV_train_12\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 216s 766ms/step - loss: 0.1391 - auc: 0.9536 - val_loss: 0.1512 - val_auc: 0.9331\n",
            "HV_train_13\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 217s 770ms/step - loss: 0.1330 - auc: 0.9577 - val_loss: 0.1469 - val_auc: 0.9363\n",
            "HV_train_14\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 216s 766ms/step - loss: 0.1292 - auc: 0.9536 - val_loss: 0.1418 - val_auc: 0.9363\n",
            "HV_train_15\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 218s 774ms/step - loss: 0.1375 - auc: 0.9506 - val_loss: 0.1481 - val_auc: 0.9380\n",
            "HV_train_16\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 215s 761ms/step - loss: 0.1320 - auc: 0.9531 - val_loss: 0.1464 - val_auc: 0.9338\n",
            "HV_train_17\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 216s 764ms/step - loss: 0.1355 - auc: 0.9523 - val_loss: 0.1482 - val_auc: 0.9360\n",
            "HV_train_18\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 213s 757ms/step - loss: 0.1309 - auc: 0.9575 - val_loss: 0.1449 - val_auc: 0.9417\n",
            "HV_train_19\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 215s 762ms/step - loss: 0.1366 - auc: 0.9465 - val_loss: 0.1434 - val_auc: 0.9432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3ALDD5NNF6Z",
        "outputId": "b7b440c7-7d6d-4372-a9cf-c93a3822c98f"
      },
      "source": [
        "#model_HV.save(directory+'model_HV')\n",
        "model_HV = load_model(directory+'model_HV')\n",
        "df_test = f.load('HV_test_5D')\n",
        "roc_auc_score(df_test['Label'].values, model_HV.predict(f.load('tests')))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_2_layer_call_and_return_conditional_losses while saving (showing 5 of 195). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embedding_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_2_layer_call_and_return_conditional_losses while saving (showing 5 of 195). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_Data/model_HV/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_Data/model_HV/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9383882121542471"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "099HbxPBeAvs"
      },
      "source": [
        "### Test train Gp2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RETjr4XFdk1x",
        "outputId": "aa55cecb-1c11-4e50-f1e9-cb6bc1c75a61"
      },
      "source": [
        "dftest_1D = to_HYPPI(load('HVindependent_test_group2').reset_index(drop=True))\n",
        "dftrain_1D = to_HYPPI(load('HVtrain_set_group2').reset_index(drop=True))\n",
        "dftrain_1D.shape,dftest_1D.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((180342, 4), (45040, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeXX8Qhtdk4b",
        "outputId": "8f80b70c-3dae-4ec0-ccba-0bf7086b1a91"
      },
      "source": [
        "# f.save(dftrain_1D,'HV_train_1D')\n",
        "# f.save(dftest_1D,'HV_test_1D')\n",
        "df_train = f.load('HV_train_1D')\n",
        "\n",
        "multiple = df_train.shape[0]//20\n",
        "\n",
        "for i in range(20):\n",
        "  print(i+1)\n",
        "  df = df_train.loc[multiple*i:multiple*(i+1)].reset_index(drop=True)\n",
        "  f.combine_AC(df,5)\n",
        "  f.save(df,'HV_train_'+str(i)+'')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCiSLDLamniy",
        "outputId": "e938b112-6c32-41fc-acdf-3118d25984ec"
      },
      "source": [
        "train_5D = f.load('HV_train_0')\n",
        "for i in range(1,20):\n",
        "  train_5D = pd.concat([train_5D,f.load('HV_train_'+str(i)+'')]).reset_index(drop=True)\n",
        "train_5D\n",
        "f.create_tokenizers(train_5D)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved tokenizers as doubleip_tkrs\n",
            "Saved tokenizer as join_tkr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-QQsLqJxabf"
      },
      "source": [
        "df_test = f.load('HV_test_1D')\n",
        "f.combine_AC(df_test,5)\n",
        "f.save(df_test,'HV_test_5D')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e7tTYFT2hRZ",
        "outputId": "4b457abf-e434-42f9-f2b9-72189fa232f3"
      },
      "source": [
        "df_test = f.load('HV_test_5D')\n",
        "tests = f.preprocess(df_test,saveTokrs=False)\n",
        "f.save(tests,'tests')\n",
        "val_tests = df_test.loc[:1500]\n",
        "f.save(val_tests,'val_tests')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6ySktXpmnmp",
        "outputId": "70e6f086-9a46-452e-deaa-8dbca9a30427"
      },
      "source": [
        "EMBEDDING_DIM_5D = 50\n",
        "VALIDATION_SPLIT = 0.2\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 1\n",
        "DROP = 0.5\n",
        "threshold = 0.918\n",
        "MAX_SEQUENCE_LENGTH_5D_J = 2000\n",
        "MAX_SEQUENCE_LENGTH_5D_dIP = 1000\n",
        "num_words_5D_J = 1000000\n",
        "num_words_5D = 500000\n",
        "\n",
        "x1_join = f.transf_model(MAX_SEQUENCE_LENGTH_5D_J,num_words_5D_J,5,0.9)\n",
        "x2_join = f.transf_model(MAX_SEQUENCE_LENGTH_5D_J,num_words_5D_J,5,0.9)\n",
        "x3_join = f.transf_model(MAX_SEQUENCE_LENGTH_5D_J,num_words_5D_J,5,0.9)\n",
        "\n",
        "x1_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x2_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x3_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x4_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x5_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x6_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "\n",
        "concatenator = Concatenate(axis=1)\n",
        "x = concatenator([x1_join.output, x2_join.output, x3_join.output, x1_doubleip.output, x2_doubleip.output, x3_doubleip.output, x4_doubleip.output, x5_doubleip.output, x6_doubleip.output])\n",
        "x = Dense(256)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation=\"sigmoid\",name=\"Final\")(x)\n",
        "model_HV = Model(inputs=[x1_join.input, x2_join.input, x3_join.input, x1_doubleip.input, x2_doubleip.input, x3_doubleip.input, x4_doubleip.input, x5_doubleip.input, x6_doubleip.input], outputs=output)\n",
        "\n",
        "model_HV.compile(loss='binary_crossentropy', optimizer='adam', metrics=AUC())\n",
        "\n",
        "#model_HV.save(directory+'model_HV')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_2_layer_call_and_return_conditional_losses while saving (showing 5 of 195). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embedding_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_2_layer_call_and_return_conditional_losses while saving (showing 5 of 195). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_Data/model_HV/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_Data/model_HV/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nVGgy3Pocw5"
      },
      "source": [
        "### 2 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m7ziLAd3Wh4",
        "outputId": "25bfc407-7a3b-43e7-ff9b-e1152257e8e3"
      },
      "source": [
        "df_test = f.load('val_tests')\n",
        "val_tests = f.preprocess(df_test,saveTokrs=False)\n",
        "model_HV = load_model(directory+'model_HV')\n",
        "names = ['HV_train_'+str(i) for i in range(20)]\n",
        "\n",
        "for name in names+names:\n",
        "  print(name)\n",
        "  df_train = f.load(name)\n",
        "  trains = f.preprocess(df_train,saveTokrs=False)\n",
        "  model_HV.fit(trains, df_train['Label'].values, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(val_tests,df_test['Label'].values))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing...\n",
            "HV_train_0\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 250s 812ms/step - loss: 0.2955 - auc: 0.6732 - val_loss: 0.2440 - val_auc: 0.8288\n",
            "HV_train_1\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 226s 800ms/step - loss: 0.2368 - auc: 0.8203 - val_loss: 0.2385 - val_auc: 0.8653\n",
            "HV_train_2\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 225s 796ms/step - loss: 0.2236 - auc: 0.8438 - val_loss: 0.2093 - val_auc: 0.8893\n",
            "HV_train_3\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 225s 799ms/step - loss: 0.2059 - auc: 0.8767 - val_loss: 0.1941 - val_auc: 0.8988\n",
            "HV_train_4\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 222s 786ms/step - loss: 0.1977 - auc: 0.8815 - val_loss: 0.1895 - val_auc: 0.9090\n",
            "HV_train_5\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 218s 772ms/step - loss: 0.1977 - auc: 0.8848 - val_loss: 0.1737 - val_auc: 0.9241\n",
            "HV_train_6\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 221s 783ms/step - loss: 0.1827 - auc: 0.9045 - val_loss: 0.1696 - val_auc: 0.9256\n",
            "HV_train_7\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 217s 769ms/step - loss: 0.1860 - auc: 0.8968 - val_loss: 0.1619 - val_auc: 0.9358\n",
            "HV_train_8\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 218s 774ms/step - loss: 0.1760 - auc: 0.8977 - val_loss: 0.1667 - val_auc: 0.9243\n",
            "HV_train_9\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 216s 767ms/step - loss: 0.1797 - auc: 0.9093 - val_loss: 0.1642 - val_auc: 0.9323\n",
            "HV_train_10\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 215s 762ms/step - loss: 0.1765 - auc: 0.9136 - val_loss: 0.1602 - val_auc: 0.9307\n",
            "HV_train_11\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 220s 779ms/step - loss: 0.1769 - auc: 0.9067 - val_loss: 0.1621 - val_auc: 0.9317\n",
            "HV_train_12\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 213s 754ms/step - loss: 0.1692 - auc: 0.9175 - val_loss: 0.1833 - val_auc: 0.9343\n",
            "HV_train_13\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 214s 758ms/step - loss: 0.1820 - auc: 0.9051 - val_loss: 0.1602 - val_auc: 0.9378\n",
            "HV_train_14\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 214s 757ms/step - loss: 0.1680 - auc: 0.9170 - val_loss: 0.1755 - val_auc: 0.9450\n",
            "HV_train_15\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 215s 764ms/step - loss: 0.1730 - auc: 0.9167 - val_loss: 0.1516 - val_auc: 0.9445\n",
            "HV_train_16\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 212s 752ms/step - loss: 0.1666 - auc: 0.9198 - val_loss: 0.1472 - val_auc: 0.9469\n",
            "HV_train_17\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 216s 765ms/step - loss: 0.1620 - auc: 0.9238 - val_loss: 0.1598 - val_auc: 0.9458\n",
            "HV_train_18\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 214s 759ms/step - loss: 0.1614 - auc: 0.9241 - val_loss: 0.1468 - val_auc: 0.9498\n",
            "HV_train_19\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 215s 762ms/step - loss: 0.1632 - auc: 0.9219 - val_loss: 0.1499 - val_auc: 0.9479\n",
            "HV_train_0\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 214s 758ms/step - loss: 0.1510 - auc: 0.9375 - val_loss: 0.1436 - val_auc: 0.9507\n",
            "HV_train_1\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 213s 756ms/step - loss: 0.1405 - auc: 0.9474 - val_loss: 0.1483 - val_auc: 0.9494\n",
            "HV_train_2\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 214s 759ms/step - loss: 0.1513 - auc: 0.9390 - val_loss: 0.1486 - val_auc: 0.9473\n",
            "HV_train_3\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 216s 765ms/step - loss: 0.1421 - auc: 0.9497 - val_loss: 0.1483 - val_auc: 0.9497\n",
            "HV_train_4\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 218s 774ms/step - loss: 0.1392 - auc: 0.9516 - val_loss: 0.1540 - val_auc: 0.9432\n",
            "HV_train_5\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 213s 755ms/step - loss: 0.1398 - auc: 0.9485 - val_loss: 0.1523 - val_auc: 0.9480\n",
            "HV_train_6\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 214s 758ms/step - loss: 0.1336 - auc: 0.9551 - val_loss: 0.1474 - val_auc: 0.9480\n",
            "HV_train_7\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 211s 748ms/step - loss: 0.1279 - auc: 0.9581 - val_loss: 0.1497 - val_auc: 0.9455\n",
            "HV_train_8\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 213s 756ms/step - loss: 0.1277 - auc: 0.9548 - val_loss: 0.1622 - val_auc: 0.9406\n",
            "HV_train_9\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 214s 758ms/step - loss: 0.1313 - auc: 0.9555 - val_loss: 0.1562 - val_auc: 0.9430\n",
            "HV_train_10\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 212s 752ms/step - loss: 0.1309 - auc: 0.9576 - val_loss: 0.1511 - val_auc: 0.9410\n",
            "HV_train_11\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 213s 754ms/step - loss: 0.1342 - auc: 0.9568 - val_loss: 0.1596 - val_auc: 0.9453\n",
            "HV_train_12\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 212s 751ms/step - loss: 0.1313 - auc: 0.9579 - val_loss: 0.1570 - val_auc: 0.9399\n",
            "HV_train_13\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 211s 749ms/step - loss: 0.1411 - auc: 0.9515 - val_loss: 0.1600 - val_auc: 0.9382\n",
            "HV_train_14\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 213s 756ms/step - loss: 0.1357 - auc: 0.9554 - val_loss: 0.1543 - val_auc: 0.9474\n",
            "HV_train_15\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 212s 752ms/step - loss: 0.1342 - auc: 0.9583 - val_loss: 0.1505 - val_auc: 0.9461\n",
            "HV_train_16\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 212s 751ms/step - loss: 0.1383 - auc: 0.9544 - val_loss: 0.1602 - val_auc: 0.9446\n",
            "HV_train_17\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 217s 768ms/step - loss: 0.1310 - auc: 0.9584 - val_loss: 0.1561 - val_auc: 0.9422\n",
            "HV_train_18\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 212s 750ms/step - loss: 0.1306 - auc: 0.9557 - val_loss: 0.1457 - val_auc: 0.9492\n",
            "HV_train_19\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 211s 750ms/step - loss: 0.1379 - auc: 0.9494 - val_loss: 0.1481 - val_auc: 0.9488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH_8zfs36dyT",
        "outputId": "639aedd4-0813-4b73-9a23-0d0d9175c37d"
      },
      "source": [
        "#model_HV.save(directory+'model_HV')\n",
        "model_HV = load_model(directory+'model_HV')\n",
        "df_test = f.load('HV_test_5D')\n",
        "roc_auc_score(df_test['Label'].values, model_HV.predict(f.load('tests')))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_2_layer_call_and_return_conditional_losses while saving (showing 5 of 195). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embedding_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_2_layer_call_and_return_conditional_losses while saving (showing 5 of 195). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_Data/model_HV/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_Data/model_HV/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9369066591164074"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbbeG-e-m5zC"
      },
      "source": [
        "### Test train Gp3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjLt47UIm4yq",
        "outputId": "6b94790d-7fca-4828-f4d5-32bcafc58ebb"
      },
      "source": [
        "dftest_1D = to_HYPPI(load('HVindependent_test_group3').reset_index(drop=True))\n",
        "dftrain_1D = to_HYPPI(load('HVtrain_set_group3').reset_index(drop=True))\n",
        "dftrain_1D.shape,dftest_1D.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((180291, 4), (44962, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Loqpw_vLm416",
        "outputId": "b39d6890-b4d4-471b-9c73-90f5fb6437fa"
      },
      "source": [
        "# f.save(dftrain_1D,'HV_train_1D')\n",
        "# f.save(dftest_1D,'HV_test_1D')\n",
        "\n",
        "df_train = f.load('HV_train_1D')\n",
        "\n",
        "multiple = df_train.shape[0]//20\n",
        "\n",
        "for i in range(20):\n",
        "  print(i+1)\n",
        "  df = df_train.loc[multiple*i:multiple*(i+1)].reset_index(drop=True)\n",
        "  f.combine_AC(df,5)\n",
        "  f.save(df,'HV_train_'+str(i)+'')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un7thPkSm448",
        "outputId": "6abcd9a3-79b0-4984-a727-3a96d5292f49"
      },
      "source": [
        "train_5D = f.load('HV_train_0')\n",
        "for i in range(1,20):\n",
        "  train_5D = pd.concat([train_5D,f.load('HV_train_'+str(i)+'')]).reset_index(drop=True)\n",
        "train_5D\n",
        "f.create_tokenizers(train_5D)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved tokenizers as doubleip_tkrs\n",
            "Saved tokenizer as join_tkr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnFqru3CnOsq"
      },
      "source": [
        "df_test = f.load('HV_test_1D')\n",
        "f.combine_AC(df_test,5)\n",
        "f.save(df_test,'HV_test_5D')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTL-0INSnOxj",
        "outputId": "b228e9ba-1fd1-4afd-811b-335143196804"
      },
      "source": [
        "df_test = f.load('HV_test_5D')\n",
        "tests = f.preprocess(df_test,saveTokrs=False)\n",
        "f.save(tests,'tests')\n",
        "val_tests = df_test.loc[:1500]\n",
        "f.save(val_tests,'val_tests')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5OTC186nQ6x",
        "outputId": "7cfc19f1-1854-49a3-fadd-13dbbaf8b271"
      },
      "source": [
        "EMBEDDING_DIM_5D = 50\n",
        "VALIDATION_SPLIT = 0.2\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 1\n",
        "DROP = 0.5\n",
        "threshold = 0.918\n",
        "MAX_SEQUENCE_LENGTH_5D_J = 2000\n",
        "MAX_SEQUENCE_LENGTH_5D_dIP = 1000\n",
        "num_words_5D_J = 1000000\n",
        "num_words_5D = 500000\n",
        "\n",
        "x1_join = f.transf_model(MAX_SEQUENCE_LENGTH_5D_J,num_words_5D_J,5,0.9)\n",
        "x2_join = f.transf_model(MAX_SEQUENCE_LENGTH_5D_J,num_words_5D_J,5,0.9)\n",
        "x3_join = f.transf_model(MAX_SEQUENCE_LENGTH_5D_J,num_words_5D_J,5,0.9)\n",
        "\n",
        "x1_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x2_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x3_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x4_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x5_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "x6_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "\n",
        "concatenator = Concatenate(axis=1)\n",
        "x = concatenator([x1_join.output, x2_join.output, x3_join.output, x1_doubleip.output, x2_doubleip.output, x3_doubleip.output, x4_doubleip.output, x5_doubleip.output, x6_doubleip.output])\n",
        "x = Dense(256)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation=\"sigmoid\",name=\"Final\")(x)\n",
        "model_HV = Model(inputs=[x1_join.input, x2_join.input, x3_join.input, x1_doubleip.input, x2_doubleip.input, x3_doubleip.input, x4_doubleip.input, x5_doubleip.input, x6_doubleip.input], outputs=output)\n",
        "\n",
        "model_HV.compile(loss='binary_crossentropy', optimizer='adam', metrics=AUC())\n",
        "\n",
        "#model_HV.save(directory+'model_HV')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_2_layer_call_and_return_conditional_losses while saving (showing 5 of 195). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embedding_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_2_layer_call_and_return_conditional_losses while saving (showing 5 of 195). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_Data/model_HV/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_Data/model_HV/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phyOr46QnRE6",
        "outputId": "5f6c62dc-1a42-4a6d-c69e-879424a5a410"
      },
      "source": [
        "df_test = f.load('val_tests')\n",
        "val_tests = f.preprocess(df_test,saveTokrs=False)\n",
        "model_HV = load_model(directory+'model_HV')\n",
        "names = ['HV_train_'+str(i) for i in range(20)]\n",
        "\n",
        "for name in names+names:\n",
        "  print(name)\n",
        "  df_train = f.load(name)\n",
        "  trains = f.preprocess(df_train,saveTokrs=False)\n",
        "  model_HV.fit(trains, df_train['Label'].values, epochs=1, batch_size=32, validation_data=(val_tests,df_test['Label'].values))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing...\n",
            "HV_train_0\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 265s 868ms/step - loss: 0.3028 - auc: 0.6716 - val_loss: 0.2539 - val_auc: 0.8342\n",
            "HV_train_1\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 249s 882ms/step - loss: 0.2395 - auc: 0.8218 - val_loss: 0.1959 - val_auc: 0.8711\n",
            "HV_train_2\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 243s 863ms/step - loss: 0.2175 - auc: 0.8507 - val_loss: 0.1984 - val_auc: 0.8936\n",
            "HV_train_3\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 243s 863ms/step - loss: 0.2055 - auc: 0.8639 - val_loss: 0.1950 - val_auc: 0.9069\n",
            "HV_train_4\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 844ms/step - loss: 0.1965 - auc: 0.8833 - val_loss: 0.1719 - val_auc: 0.9157\n",
            "HV_train_5\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 248s 879ms/step - loss: 0.1909 - auc: 0.8921 - val_loss: 0.1679 - val_auc: 0.9169\n",
            "HV_train_6\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 240s 851ms/step - loss: 0.1837 - auc: 0.8991 - val_loss: 0.1711 - val_auc: 0.9146\n",
            "HV_train_7\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 239s 849ms/step - loss: 0.1829 - auc: 0.8944 - val_loss: 0.1661 - val_auc: 0.9193\n",
            "HV_train_8\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 239s 849ms/step - loss: 0.1879 - auc: 0.8988 - val_loss: 0.1495 - val_auc: 0.9349\n",
            "HV_train_9\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 244s 866ms/step - loss: 0.1806 - auc: 0.8977 - val_loss: 0.1497 - val_auc: 0.9408\n",
            "HV_train_10\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 239s 848ms/step - loss: 0.1737 - auc: 0.9132 - val_loss: 0.1733 - val_auc: 0.9384\n",
            "HV_train_11\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 242s 857ms/step - loss: 0.1806 - auc: 0.9022 - val_loss: 0.1579 - val_auc: 0.9411\n",
            "HV_train_12\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 240s 851ms/step - loss: 0.1687 - auc: 0.9112 - val_loss: 0.1393 - val_auc: 0.9403\n",
            "HV_train_13\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 244s 866ms/step - loss: 0.1643 - auc: 0.9209 - val_loss: 0.1357 - val_auc: 0.9483\n",
            "HV_train_14\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 842ms/step - loss: 0.1639 - auc: 0.9267 - val_loss: 0.1336 - val_auc: 0.9478\n",
            "HV_train_15\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 241s 853ms/step - loss: 0.1724 - auc: 0.9152 - val_loss: 0.1354 - val_auc: 0.9470\n",
            "HV_train_16\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 843ms/step - loss: 0.1621 - auc: 0.9224 - val_loss: 0.1537 - val_auc: 0.9451\n",
            "HV_train_17\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 240s 850ms/step - loss: 0.1669 - auc: 0.9204 - val_loss: 0.1387 - val_auc: 0.9427\n",
            "HV_train_18\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 844ms/step - loss: 0.1689 - auc: 0.9207 - val_loss: 0.1462 - val_auc: 0.9514\n",
            "HV_train_19\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 239s 846ms/step - loss: 0.1614 - auc: 0.9288 - val_loss: 0.1378 - val_auc: 0.9489\n",
            "HV_train_0\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 843ms/step - loss: 0.1571 - auc: 0.9382 - val_loss: 0.1310 - val_auc: 0.9501\n",
            "HV_train_1\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 843ms/step - loss: 0.1491 - auc: 0.9393 - val_loss: 0.1408 - val_auc: 0.9450\n",
            "HV_train_2\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 843ms/step - loss: 0.1418 - auc: 0.9467 - val_loss: 0.1413 - val_auc: 0.9425\n",
            "HV_train_3\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 239s 846ms/step - loss: 0.1368 - auc: 0.9513 - val_loss: 0.1405 - val_auc: 0.9405\n",
            "HV_train_4\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 844ms/step - loss: 0.1382 - auc: 0.9527 - val_loss: 0.1414 - val_auc: 0.9435\n",
            "HV_train_5\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 843ms/step - loss: 0.1331 - auc: 0.9535 - val_loss: 0.1387 - val_auc: 0.9435\n",
            "HV_train_6\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 244s 864ms/step - loss: 0.1325 - auc: 0.9520 - val_loss: 0.1419 - val_auc: 0.9433\n",
            "HV_train_7\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 237s 842ms/step - loss: 0.1362 - auc: 0.9516 - val_loss: 0.1370 - val_auc: 0.9402\n",
            "HV_train_8\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 844ms/step - loss: 0.1422 - auc: 0.9547 - val_loss: 0.1304 - val_auc: 0.9541\n",
            "HV_train_9\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 844ms/step - loss: 0.1360 - auc: 0.9527 - val_loss: 0.1363 - val_auc: 0.9467\n",
            "HV_train_10\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 843ms/step - loss: 0.1298 - auc: 0.9569 - val_loss: 0.1363 - val_auc: 0.9486\n",
            "HV_train_11\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 843ms/step - loss: 0.1421 - auc: 0.9470 - val_loss: 0.1368 - val_auc: 0.9522\n",
            "HV_train_12\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 845ms/step - loss: 0.1309 - auc: 0.9530 - val_loss: 0.1295 - val_auc: 0.9560\n",
            "HV_train_13\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 843ms/step - loss: 0.1239 - auc: 0.9631 - val_loss: 0.1292 - val_auc: 0.9515\n",
            "HV_train_14\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 843ms/step - loss: 0.1284 - auc: 0.9593 - val_loss: 0.1304 - val_auc: 0.9470\n",
            "HV_train_15\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 843ms/step - loss: 0.1361 - auc: 0.9541 - val_loss: 0.1326 - val_auc: 0.9477\n",
            "HV_train_16\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 844ms/step - loss: 0.1278 - auc: 0.9579 - val_loss: 0.1382 - val_auc: 0.9378\n",
            "HV_train_17\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 845ms/step - loss: 0.1286 - auc: 0.9581 - val_loss: 0.1362 - val_auc: 0.9489\n",
            "HV_train_18\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 238s 844ms/step - loss: 0.1349 - auc: 0.9538 - val_loss: 0.1337 - val_auc: 0.9495\n",
            "HV_train_19\n",
            "Preprocessing...\n",
            "282/282 [==============================] - 244s 865ms/step - loss: 0.1325 - auc: 0.9579 - val_loss: 0.1383 - val_auc: 0.9484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvltMM2Z4716",
        "outputId": "58849878-348a-49fc-daff-2d2638dce5ec"
      },
      "source": [
        "#model_HV.save(directory+'model_HV')\n",
        "model_HV = load_model(directory+'model_HV')\n",
        "df_test = f.load('HV_test_5D')\n",
        "roc_auc_score(df_test['Label'].values, model_HV.predict(f.load('tests')))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, embedding_2_layer_call_fn while saving (showing 5 of 195). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, embedding_2_layer_call_fn while saving (showing 5 of 195). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_Data/model_HV/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML_Data/model_HV/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9427204120284928"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    }
  ]
}