{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "5FCV_final_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1JEAGoGlWUP_i1zUtTveHMj_HDMKynNMA",
      "authorship_tag": "ABX9TyPrhX3glRze64+2/fvtjqUh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhil-mathews/MastersPr_Predicting-Human-Pathogen-PPIs-using-Natural-Language-Processing-methods/blob/main/4.Final_model/5FCV_final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDfJD8MItdQh",
        "outputId": "6ac37c69-2e5f-4c3d-8e36-b3e41687a892"
      },
      "source": [
        "import pandas as pd\n",
        "#Google colab does not have pickle\n",
        "try:\n",
        "  import pickle5 as pickle\n",
        "except:\n",
        "  !pip install pickle5\n",
        "  import pickle5 as pickle\n",
        "import os\n",
        "import seaborn as sns\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D,Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding,Concatenate\n",
        "from keras.models import Model,load_model\n",
        "from sklearn.metrics import roc_auc_score,confusion_matrix,roc_curve, auc\n",
        "from numpy import random\n",
        "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.metrics import AUC\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/ML_Data/')\n",
        "import functions as f"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pickle5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/4c/5c4dd0462c8d3a6bc4af500a6af240763c2ebd1efdc736fc2c946d44b70a/pickle5-0.0.11.tar.gz (132kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 26.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30kB 21.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 51kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 61kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 71kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 81kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 92kB 14.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 102kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 112kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 122kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 13.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp37-cp37m-linux_x86_64.whl size=219251 sha256=0ed2d4ee6d1b98985a5e2e268de3aa39474b4199aacf14dce72f80e17bdfc1d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/90/95/f889ca4aa8b0e0c7f21c8470b6f5d6032f0390a3a141a9a3bd\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "b85EqgVHtiCT",
        "outputId": "6fdd4d52-461c-4635-f435-bf78b4ed7000"
      },
      "source": [
        "def load_data(D=1,randomize=False):\n",
        "    try:\n",
        "        with open('/content/drive/MyDrive/ML_Data/df_train_'+str(D)+'D.pickle', 'rb') as handle:\n",
        "            df_train = pickle.load(handle)\n",
        "    except:\n",
        "        df_train = pd.read_pickle(\"C:/Users/nik00/py/proj/hyppi-train.pkl\")\n",
        "    try:\n",
        "        with open('/content/drive/MyDrive/ML_Data/df_test_'+str(D)+'D.pickle', 'rb') as handle:\n",
        "            df_test = pickle.load(handle)\n",
        "    except:\n",
        "        df_test = pd.read_pickle(\"C:/Users/nik00/py/proj/hyppi-independent.pkl\")\n",
        "    if randomize:\n",
        "        return shuff_together(df_train,df_test)\n",
        "    else:\n",
        "        return df_train,df_test\n",
        "\n",
        "df_train,df_test = load_data(5)\n",
        "print('The data used will be:')\n",
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The data used will be:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Human</th>\n",
              "      <th>Yersinia</th>\n",
              "      <th>Joined</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[MKDKQ, KDKQK, DKQKK, KQKKK, QKKKK, KKKKE, KKK...</td>\n",
              "      <td>[MAKAS, AKASR, KASRH, ASRHN, SRHNL, RHNLS, HNL...</td>\n",
              "      <td>[MKDKQ, KDKQK, DKQKK, KQKKK, QKKKK, KKKKE, KKK...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[MSWSG, SWSGL, WSGLL, SGLLH, GLLHG, LLHGL, LHG...</td>\n",
              "      <td>[MQHVT, QHVTG, HVTGS, VTGSK, TGSKR, GSKRR, SKR...</td>\n",
              "      <td>[MSWSG, SWSGL, WSGLL, SGLLH, GLLHG, LLHGL, LHG...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[MSLFD, SLFDL, LFDLF, FDLFR, DLFRG, LFRGF, FRG...</td>\n",
              "      <td>[MAELP, AELPA, ELPAK, LPAKR, PAKRR, AKRRF, KRR...</td>\n",
              "      <td>[MSLFD, SLFDL, LFDLF, FDLFR, DLFRG, LFRGF, FRG...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[MAVAP, AVAPR, VAPRL, APRLF, PRLFG, RLFGG, LFG...</td>\n",
              "      <td>[MRIFA, RIFAI, IFAIS, FAISC, AISCS, ISCSS, SCS...</td>\n",
              "      <td>[MAVAP, AVAPR, VAPRL, APRLF, PRLFG, RLFGG, LFG...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[MSTIQ, STIQS, TIQSE, IQSET, QSETD, SETDC, ETD...</td>\n",
              "      <td>[MSYAF, SYAFP, YAFPG, AFPGT, FPGTF, PGTFP, GTF...</td>\n",
              "      <td>[MSTIQ, STIQS, TIQSE, IQSET, QSETD, SETDC, ETD...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6265</th>\n",
              "      <td>[MSYFG, SYFGE, YFGEH, FGEHF, GEHFW, EHFWG, HFW...</td>\n",
              "      <td>[MITTD, ITTDG, TTDGN, TDGNS, DGNSA, GNSAV, NSA...</td>\n",
              "      <td>[MSYFG, SYFGE, YFGEH, FGEHF, GEHFW, EHFWG, HFW...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6266</th>\n",
              "      <td>[MTVGK, TVGKS, VGKSS, GKSSK, KSSKM, SSKML, SKM...</td>\n",
              "      <td>[MSQPP, SQPPF, QPPFW, PPFWQ, PFWQQ, FWQQK, WQQ...</td>\n",
              "      <td>[MTVGK, TVGKS, VGKSS, GKSSK, KSSKM, SSKML, SKM...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6267</th>\n",
              "      <td>[MNNLS, NNLSF, NLSFS, LSFSE, SFSEL, FSELC, SEL...</td>\n",
              "      <td>[MSEDR, SEDRH, EDRHQ, DRHQQ, RHQQR, HQQRQ, QQR...</td>\n",
              "      <td>[MNNLS, NNLSF, NLSFS, LSFSE, SFSEL, FSELC, SEL...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6268</th>\n",
              "      <td>[MAPEI, APEIN, PEINL, EINLP, INLPG, NLPGP, LPG...</td>\n",
              "      <td>[MKNLS, KNLSF, NLSFV, LSFVA, SFVAG, FVAGL, VAG...</td>\n",
              "      <td>[MAPEI, APEIN, PEINL, EINLP, INLPG, NLPGP, LPG...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6269</th>\n",
              "      <td>[MMLGT, MLGTE, LGTEG, GTEGG, TEGGE, EGGEG, GGE...</td>\n",
              "      <td>[MVMKK, VMKKI, MKKIA, KKIAC, KIACL, IACLS, ACL...</td>\n",
              "      <td>[MMLGT, MLGTE, LGTEG, GTEGG, TEGGE, EGGEG, GGE...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6270 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Human  ... label\n",
              "0     [MKDKQ, KDKQK, DKQKK, KQKKK, QKKKK, KKKKE, KKK...  ...     1\n",
              "1     [MSWSG, SWSGL, WSGLL, SGLLH, GLLHG, LLHGL, LHG...  ...     0\n",
              "2     [MSLFD, SLFDL, LFDLF, FDLFR, DLFRG, LFRGF, FRG...  ...     1\n",
              "3     [MAVAP, AVAPR, VAPRL, APRLF, PRLFG, RLFGG, LFG...  ...     0\n",
              "4     [MSTIQ, STIQS, TIQSE, IQSET, QSETD, SETDC, ETD...  ...     0\n",
              "...                                                 ...  ...   ...\n",
              "6265  [MSYFG, SYFGE, YFGEH, FGEHF, GEHFW, EHFWG, HFW...  ...     1\n",
              "6266  [MTVGK, TVGKS, VGKSS, GKSSK, KSSKM, SSKML, SKM...  ...     1\n",
              "6267  [MNNLS, NNLSF, NLSFS, LSFSE, SFSEL, FSELC, SEL...  ...     0\n",
              "6268  [MAPEI, APEIN, PEINL, EINLP, INLPG, NLPGP, LPG...  ...     1\n",
              "6269  [MMLGT, MLGTE, LGTEG, GTEGG, TEGGE, EGGEG, GGE...  ...     1\n",
              "\n",
              "[6270 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLJ9rdiqplto"
      },
      "source": [
        "### Stratified K-Fold CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQsuLbRLphMb"
      },
      "source": [
        "# skf = StratifiedKFold(n_splits=5,shuffle=True)\n",
        "# X = df_train[['Human','Yersinia']]\n",
        "# y = df_train[['label']]\n",
        "# skf.get_n_splits(X, y)\n",
        "# trains = []\n",
        "# tests = []\n",
        "# for train_index, test_index in skf.split(X, y):\n",
        "#   trains.append(df_train.iloc[train_index].reset_index(drop=True))\n",
        "#   tests.append(df_train.iloc[test_index].reset_index(drop=True))\n",
        "\n",
        "# cv_data = (trains,tests)\n",
        "# f.save(cv_data,'5Fcrossval_data')\n",
        "\n",
        "five_trains,five_tests = f.load('5Fcrossval_data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4n859FLqIJ4",
        "outputId": "89f5dbc5-7869-4731-ccf0-0f7428193cbb"
      },
      "source": [
        "EMBEDDING_DIM_5D = 25\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 1\n",
        "DROP = 0.5\n",
        "MAX_SEQUENCE_LENGTH_5D_J = 2000\n",
        "MAX_SEQUENCE_LENGTH_5D_dIP = 1000\n",
        "num_words_5D_J = 1000000\n",
        "num_words_5D = 500000\n",
        "scores = []\n",
        "\n",
        "for i in range(5):\n",
        "  df_train,df_test = five_trains[i],five_tests[i]\n",
        "  print(\"Fold\",i+1)\n",
        "  trains = f.preprocess(df_train,saveTokrs=False)\n",
        "  tests = f.preprocess(df_test,saveTokrs=False)\n",
        "  x1_join = f.transf_model(MAX_SEQUENCE_LENGTH_5D_J,num_words_5D_J,5,0.9)\n",
        "  x2_join = f.transf_model(MAX_SEQUENCE_LENGTH_5D_J,num_words_5D_J,5,0.9)\n",
        "  x3_join = f.transf_model(MAX_SEQUENCE_LENGTH_5D_J,num_words_5D_J,5,0.9)\n",
        "\n",
        "  x1_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "  x2_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "  x3_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "  x4_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "  x5_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "  x6_doubleip = f.conv_model(MAX_SEQUENCE_LENGTH_5D_dIP,EMBEDDING_DIM_5D,num_words_5D,DROP)\n",
        "\n",
        "  concatenator = Concatenate(axis=1)\n",
        "  x = concatenator([x1_join.output, x2_join.output, x3_join.output, x1_doubleip.output, x2_doubleip.output, x3_doubleip.output, x4_doubleip.output, x5_doubleip.output, x6_doubleip.output])\n",
        "  x = Dense(256)(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  output = Dense(1, activation=\"sigmoid\",name=\"Final\")(x)\n",
        "  model_final = Model(inputs=[x1_join.input, x2_join.input, x3_join.input, x1_doubleip.input, x2_doubleip.input, x3_doubleip.input, x4_doubleip.input, x5_doubleip.input, x6_doubleip.input], outputs=output)\n",
        "\n",
        "  model_final.compile(loss='binary_crossentropy', optimizer='adam', metrics=AUC())\n",
        "\n",
        "  model_final.fit(trains, df_train['label'].values, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(tests,df_test['label'].values))\n",
        "  score = roc_auc_score(df_test['label'].values, model_final.predict(tests))\n",
        "  score = round(score,3)\n",
        "  scores.append(score)\n",
        "  #print(\"Score is\",score)\n",
        "\n",
        "print(\"AUC by cross validation is\",round(sum(scores) / len(scores),2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "Preprocessing...\n",
            "Preprocessing...\n",
            "314/314 [==============================] - 192s 589ms/step - loss: 0.6215 - auc_1: 0.7465 - val_loss: 0.4193 - val_auc_1: 0.9202\n",
            "Fold 2\n",
            "Preprocessing...\n",
            "Preprocessing...\n",
            "314/314 [==============================] - 178s 545ms/step - loss: 0.6403 - auc_2: 0.7196 - val_loss: 0.4748 - val_auc_2: 0.9003\n",
            "Fold 3\n",
            "Preprocessing...\n",
            "Preprocessing...\n",
            "314/314 [==============================] - 191s 586ms/step - loss: 0.6233 - auc_3: 0.7352 - val_loss: 0.4017 - val_auc_3: 0.9064\n",
            "Fold 4\n",
            "Preprocessing...\n",
            "Preprocessing...\n",
            "314/314 [==============================] - 176s 541ms/step - loss: 0.6434 - auc_4: 0.7259 - val_loss: 0.4040 - val_auc_4: 0.9183\n",
            "Fold 5\n",
            "Preprocessing...\n",
            "Preprocessing...\n",
            "314/314 [==============================] - 178s 543ms/step - loss: 0.6448 - auc_5: 0.7248 - val_loss: 0.4076 - val_auc_5: 0.9051\n",
            "AUC by cross validation is 0.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD8tiKsCqQw_",
        "outputId": "3482737a-e10e-49d7-ba52-d079940e276f"
      },
      "source": [
        "print(\"AUC by 3 decimal places\",round(sum(scores) / len(scores),3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC by 3 decimal places 0.91\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}